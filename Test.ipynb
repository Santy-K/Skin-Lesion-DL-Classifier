{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ButEMboKPKU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.amp import autocast\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "import time\n",
        "import torchvision.transforms as v2\n",
        "from collections import Counter\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#Fix for h5py sometimes not being able to open files in parallel\n",
        "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
        "import h5py\n",
        "\n",
        "class networkTraining():\n",
        "    \"\"\"Class for training and testing a neural network model.\n",
        "    This class handles the training and testing process, including saving the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, optimizer, criterion):\n",
        "        \"\"\"Creates the network training class.\n",
        "        This class handles the training and testing process, including saving the model.\n",
        "\n",
        "        Args:\n",
        "            model: Model to be trained.\n",
        "            optimizer: Optimizer to be used.\n",
        "            criterion: Loss function to be used.\n",
        "        \"\"\"\n",
        "        self.device_type = get_device()\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = torch.device(self.device_type)\n",
        "        self.model.to(self.device, non_blocking=True)\n",
        "        self.history = {}\n",
        "\n",
        "    #Adapted fromkuzu_main.py, hw1 of COMP9444\n",
        "    def train(self, train_loader: DataLoader, epoch:int=0, name:str=\"train\"):\n",
        "        \"\"\"Trains the model for one epoch using the given data loader. Epoch is used for logging purposes.\n",
        "\n",
        "        Args:\n",
        "            train_loader (DataLoader): DataLoader for the training data.\n",
        "            epoch (int, optional): Epoch of the cycle. Used for logging. Defaults to 0.\n",
        "        \"\"\"\n",
        "        self.model.train()\n",
        "        correct = 0\n",
        "        loss_total = 0\n",
        "        total_images = 0\n",
        "\n",
        "        t = time.time()\n",
        "        conf_matrix = np.zeros((3, 3))\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(self.device, non_blocking=True), target.to(self.device, non_blocking=True)\n",
        "            target = target.long()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            with autocast(device_type=self.device_type):\n",
        "                outputs = self.model(data)\n",
        "                loss = self.criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            loss_total += loss.item()\n",
        "\n",
        "            total_images += len(data)\n",
        "\n",
        "            conf_matrix += confusion_matrix(target.cpu(), pred.cpu())\n",
        "\n",
        "            print(f\"Train Epoch: {epoch} [{total_images}/{len(train_loader.dataset)}]\")\n",
        "\n",
        "        self.history.setdefault(epoch, {})[f\"{name}_loss\"] = loss_total / (batch_idx+1)\n",
        "        self.history[epoch][f\"{name}_accuracy\"] = correct / len(train_loader.dataset)\n",
        "        self.history[epoch][f\"{name}_time\"] = time.time() - t\n",
        "        print(f\"Train Epoch: {epoch}\\t Loss: {loss_total / (batch_idx+1):.6f} \\t Accuracy: {correct}/{len(train_loader.dataset)} ({correct / len(train_loader.dataset):.2%})\")\n",
        "        print(f\"Confusion matrix for train:\")\n",
        "        print(conf_matrix)\n",
        "\n",
        "    #Adapted fromkuzu_main.py, hw1 of COMP9444\n",
        "    def test(self, test_loader: DataLoader, name:str=\"test\", epoch:int=0):\n",
        "        \"\"\"Tests the model using the given data loader. Name is used for logging purposes.\n",
        "\n",
        "        Args:\n",
        "            train_loader (DataLoader): DataLoader for the training data.\n",
        "            name (str, optional): Name of the test set. Used for logging. Defaults to \"Test\".\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total_samples = 0\n",
        "        batches = len(test_loader)\n",
        "\n",
        "        t = time.time()\n",
        "\n",
        "        #inference_mode is faster than no_grad\n",
        "        with torch.inference_mode():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                with autocast(self.device_type):\n",
        "                    outputs = self.model(data)\n",
        "                    target = target.long()\n",
        "                    loss = self.criterion(outputs, target)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                _, pred = torch.max(outputs, 1)\n",
        "                correct += (pred == target).sum().item()\n",
        "                total_samples += target.size(0)\n",
        "\n",
        "        self.history.setdefault(epoch, {})[f\"{name}_loss\"] = test_loss / (batches)\n",
        "        self.history[epoch][f\"{name}_accuracy\"] = correct / len(test_loader.dataset)\n",
        "        self.history[epoch][f\"{name}_time\"] = time.time() - t\n",
        "\n",
        "        print(f\"\\n{name}: Average loss: {test_loss / batches:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({correct / len(test_loader.dataset):.2%}%)\\n\")\n",
        "\n",
        "        #Confusion matrix\n",
        "        conf_matrix = confusion_matrix(target.cpu(), pred.cpu())\n",
        "        print(f\"Confusion matrix for {name}:\")\n",
        "        print(conf_matrix)\n",
        "\n",
        "        return correct / (len(test_loader.dataset))\n",
        "\n",
        "\n",
        "    def save_model(self, path, model_name=\"history/model\"):\n",
        "        #Save the model\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "\n",
        "        #Save the history of the model\n",
        "        df = pd.DataFrame(self.history).T\n",
        "        df = df.rename_axis('epoch').reset_index()\n",
        "        #Create the folder if it does not exist\n",
        "        os.makedirs(os.path.dirname(model_name), exist_ok=True)\n",
        "        df.to_csv(f\"{model_name}_history.csv\", index=False)\n",
        "\n",
        "    def plot_model(self, path='plot.jpg', model_name=\"model\"):\n",
        "        df = pd.DataFrame(self.history).T\n",
        "        df = df.rename_axis(\"epoch\").reset_index()\n",
        "\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "        #Loss and accuracy\n",
        "        loss_list = [x for x in list(df) if \"loss\" in x]\n",
        "        acc_list = [x for x in list(df) if \"accuracy\" in x]\n",
        "\n",
        "        for loss in loss_list:\n",
        "            ax[0].plot(df[\"epoch\"], df[loss], label=loss)\n",
        "\n",
        "        for acc in acc_list:\n",
        "            ax[1].plot(df[\"epoch\"], df[acc], label=acc)\n",
        "\n",
        "        #Labelling and formatting\n",
        "        ax[0].set_title(\"Loss\")\n",
        "        ax[0].set_xlabel(\"Epoch\")\n",
        "        ax[0].set_ylabel(\"Loss\")\n",
        "        ax[0].legend()\n",
        "\n",
        "        ax[1].set_title(\"Accuracy\")\n",
        "        ax[1].set_xlabel(\"Epoch\")\n",
        "        ax[1].set_ylabel(\"Accuracy\")\n",
        "        ax[1].yaxis.set_major_formatter(FuncFormatter('{0:.0%}'.format))\n",
        "        ax[1].set_ylim((0, 1))\n",
        "        ax[1].legend()\n",
        "\n",
        "        fig.tight_layout()\n",
        "        fig.subplots_adjust(top=0.9)\n",
        "\n",
        "        #Title\n",
        "        fig.suptitle(f\"{model_name} Performance\")\n",
        "        plt.savefig(path)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "def get_device():\n",
        "    \"\"\"Finds the device to be used for training and testing.\n",
        "    This is used to determine if a GPU is available.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return 'cuda'\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return 'mps'\n",
        "\n",
        "    return 'cpu'\n",
        "\n",
        "MELANOMA = 1\n",
        "NEITHER = 0\n",
        "SEB = 2\n",
        "def create_h5_from_images(csv_path: str, img_dir: str, h5_filename: str, resolution=(224, 224)):\n",
        "    \"\"\"Creates an HDF5 file from a CSV file containing images and their labels.\n",
        "    Images are stored in uint8 format, where the images are (height, width, channels).\n",
        "    The labels are stored as int.\n",
        "\n",
        "    Args:\n",
        "        csv_path (str): Path to the CSV file containing image IDs and labels in the form of 'image_id,truth'.\n",
        "        img_dir (str): Relative path to the directory containing the images.\n",
        "        h5_filename (str): Relative path to the output HDF5 file.\n",
        "        resolution (tuple, optional): Height and width of output images. Defaults to (224, 224).\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    num_samples = len(df)\n",
        "\n",
        "    with h5py.File(h5_filename, 'w', locking=False) as f:\n",
        "        image_width, image_height = resolution\n",
        "        #Metadata\n",
        "        f.attrs['resolution'] = (image_width, image_height)\n",
        "        f.attrs['num_samples'] = num_samples\n",
        "        f.attrs['num_classes'] = len(df['truth'].unique())\n",
        "\n",
        "\n",
        "        #Dataset of images and labels\n",
        "        dset_images = f.create_dataset(\"images\",\n",
        "                                       shape=(num_samples, image_height, image_width, 3),\n",
        "                                       dtype=np.uint8)\n",
        "\n",
        "        dset_labels = f.create_dataset(\"labels\", shape=(num_samples,), dtype=np.uint8)\n",
        "\n",
        "        for i, row in df.iterrows():\n",
        "            img_id = row['image_id']\n",
        "            label  = row['truth']  # Labelling\n",
        "            img_path = os.path.join(img_dir, f\"{img_id}.jpg\")\n",
        "\n",
        "            #Resize\n",
        "            with Image.open(img_path).convert('RGB') as img:\n",
        "                transform = v2.Compose([\n",
        "                    v2.Resize(size=(image_height, image_width)),\n",
        "                    #v2.CenterCrop(size=(image_height, image_width)),\n",
        "                ])\n",
        "                img = transform(img)\n",
        "                # Convert to NumPy array\n",
        "                img_np = np.array(img, dtype=np.uint8)\n",
        "\n",
        "            dset_images[i] = img_np\n",
        "            dset_labels[i] = label\n",
        "\n",
        "            if i % 200 == 0:\n",
        "                print(f\"Processed {i}/{len(df['truth'])} images\")\n",
        "\n",
        "    print(f\"Created {h5_filename} with {num_samples} samples.\")\n",
        "\n",
        "class HDF5Dataset(torch.utils.data.Dataset):\n",
        "    \"\"\"HDF5 dataset class for loading images and labels from an HDF5 file.\n",
        "    \"\"\"\n",
        "    def __init__(self, filepath: str, transform:str=None):\n",
        "        \"\"\"Create a pytorch dataset from an HDF5 file containing images and labels.\n",
        "        The images are stored in uint8 format, where the images are (height, width, channels).\n",
        "        The labels are stored as int.\n",
        "        The dataset is read-only and the file is closed after reading.\n",
        "\n",
        "        Args:\n",
        "            filepath (str): Relative path to the HDF5 file.\n",
        "            transform (str, optional): Transformation of the dataset if required. Defaults to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.filepath = filepath\n",
        "        self.transform = transform\n",
        "\n",
        "        with h5py.File(filepath, 'r') as f:\n",
        "            self.images = f['images'][:]\n",
        "            self.labels = f['labels'][:]\n",
        "            self.length = len(self.labels)\n",
        "            self.all_labels = np.array(f['labels'], dtype=np.uint8)\n",
        "            try:\n",
        "                self.resolution = f.attrs['size']\n",
        "            except KeyError:\n",
        "                self.resolution = (self.images.shape[1], self.images.shape[2])\n",
        "\n",
        "        self.classes = np.unique(self.all_labels)\n",
        "\n",
        "        self.file = None # Initialize file to None\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Allows for each worker to open the file independently\n",
        "        if self.file is None:\n",
        "            self.file = h5py.File(self.filepath, 'r')\n",
        "\n",
        "        image = self.file['images'][idx]\n",
        "        label = self.file['labels'][idx]\n",
        "\n",
        "        image = Image.fromarray(image, 'RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def save_transformed_image(tensor, filename, output_dir=\"transformed_images\"):\n",
        "    #Saves a transformed image tensor to a file.\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    # Add back the mean and std if you want to visualize the original color space\n",
        "    mean = torch.tensor([0.5, 0.5, 0.5]).to(tensor.device)[:, None, None]\n",
        "    std = torch.tensor([0.5, 0.5, 0.5]).to(tensor.device)[:, None, None]\n",
        "    img = tensor * std + mean\n",
        "    img = img.clamp(0, 1)\n",
        "    img = Image.fromarray((img.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    img.save(filepath)\n",
        "\n",
        "def add_truth_column(raw: str, modified: str):\n",
        "    \"\"\"Given a csv file with image_id and labels, add a column for truth values.\n",
        "    0 - neither melanoma nor seb\n",
        "    1 - melanoma\n",
        "    2 - seborrheic keratosis\n",
        "\n",
        "    Args:\n",
        "        raw (str): Path to the raw csv file with image_id and labels.\n",
        "        modified (str): Path to the modified csv file with image_id and truth values.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(raw)\n",
        "    output_file = modified\n",
        "    print(df.shape)\n",
        "    df.insert(len(df.columns), \"truth\", NEITHER)\n",
        "    for index, row in df.iterrows():\n",
        "        #intially truth is 0\n",
        "        # assign melanoma as 1\n",
        "        if row['melanoma'] == 1.0 :\n",
        "            df.at[index, 'truth'] = MELANOMA\n",
        "        # assign seb as 2\n",
        "        elif row['seborrheic_keratosis'] == 1.0 :\n",
        "            df.at[index, 'truth'] = SEB\n",
        "\n",
        "    df.to_csv(output_file)\n",
        "\n",
        "def print_label_distribution(h5_file_path):\n",
        "    with h5py.File(h5_file_path, 'r') as f:\n",
        "        labels = f['labels'][:]\n",
        "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "        for label, count in zip(unique_labels, counts):\n",
        "            print(f\"Label {label}: {count} samples\")\n",
        "    return 0\n",
        "\n",
        "def count_samples(dataloader):\n",
        "    labels = np.concatenate([labels.numpy() for _, labels in dataloader])\n",
        "    return Counter(labels)\n",
        "\n",
        "def seed_program(seed=1):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "def convertdata():\n",
        "    #Example usage of dataset creation\n",
        "    add_truth_column(\"data/train.csv\", \"data/train_truth_1.csv\")\n",
        "    add_truth_column(\"data/validation.csv\", \"data/validation_truth.csv\")\n",
        "    add_truth_column(\"data/test.csv\", \"data/test_truth_1.csv\")\n",
        "    create_h5_from_images(\"data/train_truth_1.csv\", \"data/train\", \"data/train.h5\", (128, 128))\n",
        "    create_h5_from_images(\"data/validation_truth.csv\", \"data/validation\", \"data/valid.h5\", (128, 128))\n",
        "    create_h5_from_images(\"data/test_truth_1.csv\", \"data/test\", \"data/test.h5\", (128, 128))\n",
        "\n",
        "    #We can see the distribution of the labels in the dataset\n",
        "    print_label_distribution(\"data/train.h5\")\n",
        "    print_label_distribution(\"data/valid.h5\")\n",
        "    print_label_distribution(\"data/test.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XG3_Wyy7-yd-"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "def MobileNetV3Model(num_classes=3):\n",
        "    model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)\n",
        "    #Freeze the layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    # Change the last layer to match the number of classes\n",
        "    in_features = 960\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(in_features, 120),       \n",
        "        nn.BatchNorm1d(120),               \n",
        "        nn.ReLU(),                         \n",
        "        nn.Linear(120, 85),\n",
        "        nn.BatchNorm1d(85),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.2),                 \n",
        "        nn.Linear(85, num_classes)         \n",
        "    )\n",
        "    return model\n",
        "\n",
        "def AlexNetModel(num_classes=3):\n",
        "    model = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)\n",
        "    #Freeze the layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    # Change the last layer to match the number of classes\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(in_features, 120),       \n",
        "        nn.BatchNorm1d(120),               \n",
        "        nn.ReLU(),                         \n",
        "        nn.Linear(120, 85),\n",
        "        nn.BatchNorm1d(85),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.2),                 \n",
        "        nn.Linear(85, num_classes)    \n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iycKVOcgFhD_",
        "outputId": "c70392d6-dbaa-468f-be04-d86d5501861d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Radha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transforms\n",
            "Data size:  2750\n",
            "Class counts:  [1843  386  521]\n",
            "Data loading\n",
            "Train size:  2337 Counter({np.uint8(0): 1566, np.uint8(2): 443, np.uint8(1): 328})\n",
            "Valid size:  413 Counter({np.uint8(0): 277, np.uint8(2): 78, np.uint8(1): 58})\n",
            "Training epoch:  0\n",
            "Train Epoch: 0 [256/2337]\n",
            "Train Epoch: 0 [512/2337]\n",
            "Train Epoch: 0 [768/2337]\n",
            "Train Epoch: 0 [1024/2337]\n",
            "Train Epoch: 0 [1280/2337]\n",
            "Train Epoch: 0 [1536/2337]\n",
            "Train Epoch: 0 [1792/2337]\n",
            "Train Epoch: 0 [2048/2337]\n",
            "Train Epoch: 0 [2304/2337]\n",
            "Train Epoch: 0 [2337/2337]\n",
            "Train Epoch: 0\t Loss: 1.056269 \t Accuracy: 1045/2337 (44.72%)\n",
            "Confusion matrix for train:\n",
            "[[122. 267. 388.]\n",
            " [ 50. 457. 274.]\n",
            " [ 92. 221. 466.]]\n",
            "Testing epoch:  0\n",
            "\n",
            "Validation: Average loss: 1.0744, Accuracy: 131/413 (31.72%%)\n",
            "\n",
            "Confusion matrix for Validation:\n",
            "[[ 68  24 185]\n",
            " [ 10  17  31]\n",
            " [ 20  12  46]]\n",
            "New best accuracy: 0.3171912832929782\n",
            "Training epoch:  1\n",
            "Train Epoch: 1 [256/2337]\n",
            "Train Epoch: 1 [512/2337]\n",
            "Train Epoch: 1 [768/2337]\n",
            "Train Epoch: 1 [1024/2337]\n",
            "Train Epoch: 1 [1280/2337]\n",
            "Train Epoch: 1 [1536/2337]\n",
            "Train Epoch: 1 [1792/2337]\n",
            "Train Epoch: 1 [2048/2337]\n",
            "Train Epoch: 1 [2304/2337]\n",
            "Train Epoch: 1 [2337/2337]\n",
            "Train Epoch: 1\t Loss: 0.905431 \t Accuracy: 1329/2337 (56.87%)\n",
            "Confusion matrix for train:\n",
            "[[257. 207. 297.]\n",
            " [ 57. 594. 130.]\n",
            " [111. 206. 478.]]\n",
            "Testing epoch:  1\n",
            "\n",
            "Validation: Average loss: 0.9924, Accuracy: 219/413 (53.03%%)\n",
            "\n",
            "Confusion matrix for Validation:\n",
            "[[169  38  70]\n",
            " [ 23  30   5]\n",
            " [ 44  14  20]]\n",
            "New best accuracy: 0.5302663438256658\n",
            "Training epoch:  2\n",
            "Train Epoch: 2 [256/2337]\n",
            "Train Epoch: 2 [512/2337]\n",
            "Train Epoch: 2 [768/2337]\n",
            "Train Epoch: 2 [1024/2337]\n",
            "Train Epoch: 2 [1280/2337]\n",
            "Train Epoch: 2 [1536/2337]\n",
            "Train Epoch: 2 [1792/2337]\n",
            "Train Epoch: 2 [2048/2337]\n",
            "Train Epoch: 2 [2304/2337]\n",
            "Train Epoch: 2 [2337/2337]\n",
            "Train Epoch: 2\t Loss: 0.872493 \t Accuracy: 1393/2337 (59.61%)\n",
            "Confusion matrix for train:\n",
            "[[362. 160. 271.]\n",
            " [ 77. 566. 108.]\n",
            " [147. 181. 465.]]\n",
            "Testing epoch:  2\n",
            "\n",
            "Validation: Average loss: 0.8812, Accuracy: 255/413 (61.74%%)\n",
            "\n",
            "Confusion matrix for Validation:\n",
            "[[212  31  34]\n",
            " [ 24  29   5]\n",
            " [ 52  12  14]]\n",
            "New best accuracy: 0.6174334140435835\n",
            "Training epoch:  3\n",
            "Train Epoch: 3 [256/2337]\n",
            "Train Epoch: 3 [512/2337]\n",
            "Train Epoch: 3 [768/2337]\n",
            "Train Epoch: 3 [1024/2337]\n",
            "Train Epoch: 3 [1280/2337]\n",
            "Train Epoch: 3 [1536/2337]\n",
            "Train Epoch: 3 [1792/2337]\n",
            "Train Epoch: 3 [2048/2337]\n",
            "Train Epoch: 3 [2304/2337]\n",
            "Train Epoch: 3 [2337/2337]\n",
            "Train Epoch: 3\t Loss: 0.837206 \t Accuracy: 1510/2337 (64.61%)\n",
            "Confusion matrix for train:\n",
            "[[428. 132. 212.]\n",
            " [ 88. 598. 105.]\n",
            " [155. 135. 484.]]\n",
            "Testing epoch:  3\n",
            "\n",
            "Validation: Average loss: 0.7925, Accuracy: 280/413 (67.80%%)\n",
            "\n",
            "Confusion matrix for Validation:\n",
            "[[237  14  26]\n",
            " [ 27  27   4]\n",
            " [ 55   7  16]]\n",
            "New best accuracy: 0.6779661016949152\n",
            "Training epoch:  4\n",
            "Train Epoch: 4 [256/2337]\n",
            "Train Epoch: 4 [512/2337]\n",
            "Train Epoch: 4 [768/2337]\n",
            "Train Epoch: 4 [1024/2337]\n",
            "Train Epoch: 4 [1280/2337]\n",
            "Train Epoch: 4 [1536/2337]\n",
            "Train Epoch: 4 [1792/2337]\n",
            "Train Epoch: 4 [2048/2337]\n",
            "Train Epoch: 4 [2304/2337]\n",
            "Train Epoch: 4 [2337/2337]\n",
            "Train Epoch: 4\t Loss: 0.830284 \t Accuracy: 1487/2337 (63.63%)\n",
            "Confusion matrix for train:\n",
            "[[430. 135. 224.]\n",
            " [ 65. 587. 137.]\n",
            " [168. 121. 470.]]\n",
            "Testing epoch:  4\n",
            "\n",
            "Validation: Average loss: 0.7506, Accuracy: 286/413 (69.25%%)\n",
            "\n",
            "Confusion matrix for Validation:\n",
            "[[239  13  25]\n",
            " [ 26  27   5]\n",
            " [ 49   9  20]]\n",
            "New best accuracy: 0.6924939467312349\n",
            "Training epoch:  5\n",
            "Train Epoch: 5 [256/2337]\n",
            "Train Epoch: 5 [512/2337]\n",
            "Train Epoch: 5 [768/2337]\n",
            "Train Epoch: 5 [1024/2337]\n",
            "Train Epoch: 5 [1280/2337]\n",
            "Train Epoch: 5 [1536/2337]\n",
            "Train Epoch: 5 [1792/2337]\n",
            "Train Epoch: 5 [2048/2337]\n",
            "Train Epoch: 5 [2304/2337]\n",
            "Train Epoch: 5 [2337/2337]\n",
            "Train Epoch: 5\t Loss: 0.795161 \t Accuracy: 1540/2337 (65.90%)\n",
            "Confusion matrix for train:\n",
            "[[454. 140. 189.]\n",
            " [ 86. 594. 115.]\n",
            " [166. 101. 492.]]\n",
            "Testing epoch:  5\n",
            "\n",
            "Validation: Average loss: 0.7283, Accuracy: 292/413 (70.70%%)\n",
            "\n",
            "Confusion matrix for Validation:\n",
            "[[241  11  25]\n",
            " [ 23  30   5]\n",
            " [ 49   8  21]]\n",
            "New best accuracy: 0.7070217917675545\n",
            "Training epoch:  6\n",
            "Train Epoch: 6 [256/2337]\n",
            "Train Epoch: 6 [512/2337]\n",
            "Train Epoch: 6 [768/2337]\n",
            "Train Epoch: 6 [1024/2337]\n",
            "Train Epoch: 6 [1280/2337]\n",
            "Train Epoch: 6 [1536/2337]\n",
            "Train Epoch: 6 [1792/2337]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m    116\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining epoch: \u001b[39m\u001b[33m\"\u001b[39m, epoch)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting epoch: \u001b[39m\u001b[33m\"\u001b[39m, epoch)\n\u001b[32m    120\u001b[39m     accuracy = \u001b[38;5;28mmax\u001b[39m(accuracy, trainer.test(valid_loader, \u001b[33m\"\u001b[39m\u001b[33mValidation\u001b[39m\u001b[33m\"\u001b[39m, epoch))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mnetworkTraining.train\u001b[39m\u001b[34m(self, train_loader, epoch, name)\u001b[39m\n\u001b[32m     53\u001b[39m t = time.time()\n\u001b[32m     54\u001b[39m conf_matrix = np.zeros((\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 288\u001b[39m, in \u001b[36mHDF5Dataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    285\u001b[39m image = Image.fromarray(image, \u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\transforms\\v2\\_container.py:51\u001b[39m, in \u001b[36mCompose.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     49\u001b[39m needs_unpacking = \u001b[38;5;28mlen\u001b[39m(inputs) > \u001b[32m1\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     outputs = \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     inputs = outputs \u001b[38;5;28;01mif\u001b[39;00m needs_unpacking \u001b[38;5;28;01melse\u001b[39;00m (outputs,)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torchvision\\transforms\\v2\\_transform.py:69\u001b[39m, in \u001b[36mTransform.forward\u001b[39m\u001b[34m(self, *inputs)\u001b[39m\n\u001b[32m     63\u001b[39m needs_transform_list = \u001b[38;5;28mself\u001b[39m._needs_transform_list(flat_inputs)\n\u001b[32m     64\u001b[39m params = \u001b[38;5;28mself\u001b[39m.make_params(\n\u001b[32m     65\u001b[39m     [inpt \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list) \u001b[38;5;28;01mif\u001b[39;00m needs_transform]\n\u001b[32m     66\u001b[39m )\n\u001b[32m     68\u001b[39m flat_outputs = [\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28mself\u001b[39m.transform(inpt, params) \u001b[38;5;28;01mif\u001b[39;00m needs_transform \u001b[38;5;28;01melse\u001b[39;00m inpt\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (inpt, needs_transform) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_inputs, needs_transform_list)\n\u001b[32m     71\u001b[39m ]\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(flat_outputs, spec)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "#Set the seed for reproducibility\n",
        "seed_program(seed=1)\n",
        "\n",
        "#0.1 Data preprocessing variables\n",
        "image_scale = (224, 224)\n",
        "\n",
        "mean_vars = [0.485, 0.456, 0.406]\n",
        "std_vars = [0.229, 0.224, 0.225]\n",
        "\n",
        "transforms_2017 = v2.Compose([\n",
        "    v2.Resize(image_scale),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=mean_vars, std=std_vars),\n",
        "    v2.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "transforms_train = v2.Compose([\n",
        "    v2.RandomResizedCrop(scale=(0.8, 1.0), size=image_scale,ratio=(0.9, 1.1)),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.RandomVerticalFlip(p=0.5),\n",
        "    v2.RandomRotation(degrees=45),\n",
        "\n",
        "    v2.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05),\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=mean_vars, std=std_vars),\n",
        "    v2.ToTensor()\n",
        "])\n",
        "\n",
        "print(\"Transforms\")\n",
        "batch_size = 256\n",
        "\n",
        "#Read Data\n",
        "data_name = \"data/all_224.h5\"\n",
        "data = HDF5Dataset(data_name)\n",
        "print(\"Data size: \", len(data))\n",
        "#Print class breakdown\n",
        "class_counts = np.bincount(data.all_labels)\n",
        "print(\"Class counts: \", class_counts)\n",
        "\n",
        "#Train, test, valid split via stratified sampling\n",
        "#2000, 550, 200\n",
        "train_idx, valid_idx, train_label, _ = train_test_split(\n",
        "    np.arange(len(data.all_labels)), data.all_labels, stratify=data.all_labels, test_size=0.15, random_state=42\n",
        ")\n",
        "print(\"Data loading\")\n",
        "train_dataset = HDF5Dataset(data_name, transform=transforms_train)\n",
        "valid_dataset = HDF5Dataset(data_name, transform=transforms_2017)\n",
        "\n",
        "train_data = torch.utils.data.Subset(train_dataset, train_idx)\n",
        "valid_data = torch.utils.data.Subset(valid_dataset, valid_idx)\n",
        "\n",
        "class_weights = 1.0 / class_counts\n",
        "weights = class_weights[train_data.dataset.all_labels[train_data.indices]]\n",
        "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
        "\n",
        "#Sizes of the datasets\n",
        "print(\"Train size: \", len(train_data), Counter(train_data.dataset.all_labels[train_data.indices]))\n",
        "print(\"Valid size: \", len(valid_data), Counter(valid_data.dataset.all_labels[valid_data.indices]))\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=batch_size,\n",
        "    sampler=sampler,\n",
        "    shuffle = False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_data,\n",
        "    batch_size=len(valid_data),\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "#Testing the data loading. This is SLOW, so only run to verify the data loading is correct.\n",
        "if 0 == 1:\n",
        "    print(\"After loading data:\")\n",
        "    print(f\"Train: {count_samples(train_loader)}\")\n",
        "    print(f\"Valid: {count_samples(valid_loader)}\")\n",
        "\n",
        "    exit()\n",
        "\n",
        "#2. Hyperparameters, standard for reference\n",
        "learning_rate = 3e-4\n",
        "num_epochs = 75\n",
        "weight_decay = 1e-4\n",
        "\n",
        "#3. Model\n",
        "#model = AlexNetModel(num_classes=3)\n",
        "model = MobileNetV3Model(num_classes=3)\n",
        "#4. Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "name = \"mobilenet\"\n",
        "accuracy = 0\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "#5. Training and testing\n",
        "trainer = networkTraining(model, optimizer, criterion)\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"Training epoch: \", epoch)\n",
        "    trainer.train(train_loader, epoch)\n",
        "\n",
        "    print(\"Testing epoch: \", epoch)\n",
        "    accuracy = max(accuracy, trainer.test(valid_loader, \"Validation\", epoch))\n",
        "    \n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model_file = f\"models/{name}_{epoch}.pth\"\n",
        "        best_epoch = epoch\n",
        "        print(f\"New best accuracy: {best_accuracy}\")\n",
        "        #Save the model\n",
        "        trainer.save_model(f\"models/{name}_{epoch}.pth\", model_name=f\"history/{name}\")\n",
        "\n",
        "#Save the model after final testing\n",
        "trainer.save_model(f\"models/{name}_{num_epochs}.pth\", model_name=f\"history/{name}\")\n",
        "\n",
        "trainer.plot_model(model_name=\"MobileNet\", path=f\"plots/{name}.jpg\")\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5yiYdz3qxDq",
        "outputId": "49bd36fc-d3cf-45e3-bedb-6776a649feb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Valid: Average loss: 0.7283, Accuracy: 292/413 (70.70%%)\n",
            "\n",
            "Confusion matrix for Valid:\n",
            "[[241  11  25]\n",
            " [ 23  30   5]\n",
            " [ 49   8  21]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7070217917675545"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = trainer.device\n",
        "BEST_MODEL_PATH = best_model_file\n",
        "\n",
        "state_dict = torch.load(BEST_MODEL_PATH, map_location=device)\n",
        "\n",
        "trainer.model.load_state_dict(state_dict)\n",
        "\n",
        "trainer.test(valid_loader, \"Valid\", 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLogXdk050Iv",
        "outputId": "2f8096d1-2c73-4006-e2a8-aa8bfa0aa162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Switched to new optimizer with LR: 1e-05\n",
            "\n",
            "Validation: Average loss: 0.7283, Accuracy: 292/413 (70.70%%)\n",
            "\n",
            "Confusion matrix for Validation:\n",
            "[[241  11  25]\n",
            " [ 23  30   5]\n",
            " [ 49   8  21]]\n",
            "Fine-tuning epoch: 5\n",
            "Train Epoch: 5 [256/2337]\n",
            "Train Epoch: 5 [512/2337]\n",
            "Train Epoch: 5 [768/2337]\n",
            "Train Epoch: 5 [1024/2337]\n",
            "Train Epoch: 5 [1280/2337]\n",
            "Train Epoch: 5 [1536/2337]\n",
            "Train Epoch: 5 [1792/2337]\n",
            "Train Epoch: 5 [2048/2337]\n",
            "Train Epoch: 5 [2304/2337]\n",
            "Train Epoch: 5 [2337/2337]\n",
            "Train Epoch: 5\t Loss: 0.775467 \t Accuracy: 1572/2337 (67.27%)\n",
            "Confusion matrix for train:\n",
            "[[445.  87. 206.]\n",
            " [ 95. 634. 105.]\n",
            " [167. 105. 493.]]\n",
            "Validating fine-tuning epoch: 5\n",
            "\n",
            "Validation FT: Average loss: 0.7337, Accuracy: 291/413 (70.46%%)\n",
            "\n",
            "Confusion matrix for Validation FT:\n",
            "[[229  14  34]\n",
            " [ 20  33   5]\n",
            " [ 40   9  29]]\n",
            "Fine-tuning epoch: 6\n",
            "Train Epoch: 6 [256/2337]\n",
            "Train Epoch: 6 [512/2337]\n",
            "Train Epoch: 6 [768/2337]\n",
            "Train Epoch: 6 [1024/2337]\n",
            "Train Epoch: 6 [1280/2337]\n",
            "Train Epoch: 6 [1536/2337]\n",
            "Train Epoch: 6 [1792/2337]\n",
            "Train Epoch: 6 [2048/2337]\n",
            "Train Epoch: 6 [2304/2337]\n",
            "Train Epoch: 6 [2337/2337]\n",
            "Train Epoch: 6\t Loss: 0.769580 \t Accuracy: 1534/2337 (65.64%)\n",
            "Confusion matrix for train:\n",
            "[[457. 136. 218.]\n",
            " [ 78. 584.  98.]\n",
            " [164. 109. 493.]]\n",
            "Validating fine-tuning epoch: 6\n",
            "\n",
            "Validation FT: Average loss: 0.7309, Accuracy: 293/413 (70.94%%)\n",
            "\n",
            "Confusion matrix for Validation FT:\n",
            "[[224  17  36]\n",
            " [ 14  35   9]\n",
            " [ 35   9  34]]\n",
            "New best accuracy: 0.7094430992736077\n",
            "\n",
            "Training finished. Best overall validation accuracy: 6.0000\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Radha\\\\Desktop\\\\COMP9444 - Neural Networks\\\\Group\\\\COMP9444\\\\plots\\\\mobilenet_ft.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     32\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNew best accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining finished. Best overall validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMobileNet_FT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplots/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_ft.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 173\u001b[39m, in \u001b[36mnetworkTraining.plot_model\u001b[39m\u001b[34m(self, path, model_name)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m#Title\u001b[39;00m\n\u001b[32m    172\u001b[39m fig.suptitle(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Performance\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m plt.show()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\matplotlib\\pyplot.py:1243\u001b[39m, in \u001b[36msavefig\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1240\u001b[39m fig = gcf()\n\u001b[32m   1241\u001b[39m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[32m   1242\u001b[39m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m res = \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[32m   1244\u001b[39m fig.canvas.draw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\matplotlib\\figure.py:3490\u001b[39m, in \u001b[36mFigure.savefig\u001b[39m\u001b[34m(self, fname, transparent, **kwargs)\u001b[39m\n\u001b[32m   3488\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes:\n\u001b[32m   3489\u001b[39m         _recursively_make_axes_transparent(stack, ax)\n\u001b[32m-> \u001b[39m\u001b[32m3490\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\matplotlib\\backend_bases.py:2184\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2181\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2182\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2183\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2184\u001b[39m         result = \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2185\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\matplotlib\\backend_bases.py:2040\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2036\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2037\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2038\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2039\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2040\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2042\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2043\u001b[39m     print_method = meth\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\matplotlib\\backends\\backend_agg.py:498\u001b[39m, in \u001b[36mFigureCanvasAgg.print_jpg\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_jpg\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    494\u001b[39m     \u001b[38;5;66;03m# savefig() has already applied savefig.facecolor; we now set it to\u001b[39;00m\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# white to make imsave() blend semi-transparent figures against an\u001b[39;00m\n\u001b[32m    496\u001b[39m     \u001b[38;5;66;03m# assumed white background.\u001b[39;00m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m mpl.rc_context({\u001b[33m\"\u001b[39m\u001b[33msavefig.facecolor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mwhite\u001b[39m\u001b[33m\"\u001b[39m}):\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjpeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\matplotlib\\backends\\backend_agg.py:430\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    429\u001b[39m FigureCanvasAgg.draw(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\matplotlib\\image.py:1644\u001b[39m, in \u001b[36mimsave\u001b[39m\u001b[34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[39m\n\u001b[32m   1642\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m   1643\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, (dpi, dpi))\n\u001b[32m-> \u001b[39m\u001b[32m1644\u001b[39m \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\PIL\\Image.py:2600\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2598\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mr+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2599\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2600\u001b[39m         fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw+b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2602\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Radha\\\\Desktop\\\\COMP9444 - Neural Networks\\\\Group\\\\COMP9444\\\\plots\\\\mobilenet_ft.jpg'"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxUAAAGMCAYAAACs64+oAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAsZxJREFUeJzs3Xd8jef7wPHPOSd7WpFBiISIGLFT1Cip2HtW7V2hVo0aNYqi1Kr5tb80tm9/tYraSc0GrU2IEatIZMh8fn9EnjpNkESSI3G9X6/nJed+7nM/13NknOvcS6MoioIQQgghhBBCZJDW0AEIIYQQQgghcjZJKoQQQgghhBDvRJIKIYQQQgghxDuRpEIIIYQQQgjxTiSpEEIIIYQQQrwTSSqEEEIIIYQQ70SSCiGEEEIIIcQ7kaRCCCGEEEII8U4kqRBCCCGEEEK8E0kqhBC5jkajwc/P7631Vq1ahUaj4ebNm2pZnTp1qFOnTtYFJ95JfHw8I0aMwNnZGa1WS4sWLQwdkhBCCCSpEEJks+Q38hqNhqNHj6Y4rygKzs7OaDQamjRpYoAIM87FxQWNRsPAgQNTnDt48CAajYbNmzenu9179+4xYcIEgoKC0v3c5OumdnTo0IFu3bq99vyrR7du3V57jQkTJujVtbCwwNPTk7FjxxIeHp7umN9kxYoVzJw5kzZt2rB69WqGDBmSqe0LIYTIGCNDByCE+DCZmZmxfv16Pv74Y73yQ4cOcefOHUxNTbM8hs6dO9OhQ4dMv9ayZcsYPXo0Tk5OmdLevXv3mDhxIi4uLpQvXz5DbQwaNIgqVarolbm4uKDT6fDx8VHLgoODGT9+PH369KFmzZpquZub21uvsWjRIqysrIiIiODXX39lypQp/Pbbbxw7dgyNRpOhuP/tt99+o1ChQvzwww+Z0p4QQojMIUmFEMIgGjVqxKZNm5g3bx5GRv/8Klq/fj2VKlXi8ePHWR6DTqdDp9NlapulS5fm8uXLfPfdd8ybNy9T234XNWvWpE2bNqmeq1atmvr1qVOnGD9+PNWqVePzzz9P1zXatGlDgQIFAOjXrx+tW7dm69at/P7773rXSC9FUXjx4gXm5uY8fPiQPHnyZLitf0tMTCQ2NhYzM7NMa1MIIT5EMvxJCGEQHTt25O+//2bv3r1qWWxsLJs3b+azzz5L9TmRkZEMGzYMZ2dnTE1NKVmyJN9//z2KoqRaf926dZQsWRIzMzMqVarE4cOH9c6nNqciNTExMXzzzTcUL14cU1NTnJ2dGTFiBDExMSnquri40KVLF5YtW8a9e/fe8irA3bt36dGjB/b29piamlK6dGlWrFihnj948KDaw9C9e3d1iNGqVave2rah1a1bF0jq/YCkN/Bz5syhdOnSmJmZYW9vT9++fXn69Kne81xcXGjSpAl79uyhcuXKmJubs2TJEjQaDQcOHOCvv/5SX4eDBw8Caf/eSJ5vs27dOkqXLo2pqSm7d+9WvxeOHj3KoEGDsLOzI0+ePPTt25fY2FiePXtGly5dyJs3L3nz5mXEiBEp2v7++++pXr06+fPnx9zcnEqVKqU63C05hu3bt1OmTBn1/3337t0p6t69e5eePXvi5OSEqakpxYoVo3///sTGxqp1nj17xuDBg9V7L168ONOnTycxMTH9/2lCCJFB0lMhhDAIFxcXqlWrxk8//UTDhg0B2LVrF2FhYXTo0CHFp/yKotCsWTMOHDhAz549KV++PHv27OGrr77i7t27KYbDHDp0iA0bNjBo0CBMTU1ZuHAhDRo04MSJE5QpUybNcSYmJtKsWTOOHj1Knz59KFWqFOfPn+eHH37gypUrbN++PcVzxowZw5o1a97aW/HgwQM++ugj9U2mnZ0du3btomfPnoSHhzN48GBKlSrFpEmTUgxJql69eprvAeD58+cpen/y5cuHVpt1ny1dv34dgPz58wPQt29fVq1aRffu3Rk0aBDBwcEsWLCAP/74g2PHjmFsbKw+9/Lly3Ts2JG+ffvSu3dvChcuzNq1a5kyZQoRERFMmzYNgFKlSqX7e+O3335j48aN+Pn5UaBAAVxcXNT5KgMHDsTBwYGJEyfy+++/s3TpUvLkyUNAQABFihRh6tSp7Ny5k5kzZ1KmTBm6dOmitjt37lyaNWtGp06diI2Nxd/fn7Zt2/LLL7/QuHFjvRiOHj3K1q1b+eKLL7C2tmbevHm0bt2akJAQ9fW6d+8eVatW5dmzZ/Tp0wcPDw/u3r3L5s2biYqKwsTEhKioKGrXrs3du3fp27cvRYoUISAggNGjRxMaGsqcOXMy9f9UCCFeSxFCiGy0cuVKBVBOnjypLFiwQLG2tlaioqIURVGUtm3bKp988omiKIpStGhRpXHjxurztm/frgDKt99+q9demzZtFI1Go1y7dk0tAxRAOXXqlFp269YtxczMTGnZsmWKWIKDg9Wy2rVrK7Vr11Yfr127VtFqtcqRI0f0rrt48WIFUI4dO6aWvRpz9+7dFTMzM+XevXuKoijKgQMHFEDZtGmTWr9nz56Ko6Oj8vjxY722O3TooNja2qqvy8mTJxVAWbly5Wte1ddLvm5qx6v3nSwj1/rmm28UQLl8+bLy6NEjJTg4WFmyZIliamqq2NvbK5GRkcqRI0cUQFm3bp3ec3fv3p2ivGjRogqg7N69O8W1ateurZQuXVqvLL3fG1qtVvnrr7/06iZ/L/j6+iqJiYlqebVq1RSNRqP069dPLYuPj1cKFy6s932iKIr6/5UsNjZWKVOmjFK3bl29ckAxMTHRi+vs2bMKoMyfP18t69Kli6LVapWTJ0+meB2SY5w8ebJiaWmpXLlyRe/8qFGjFJ1Op4SEhKR4rhBCZAUZ/iSEMJh27doRHR3NL7/8wvPnz/nll19eO/Rp586d6HQ6Bg0apFc+bNgwFEVh165deuXVqlWjUqVK6uMiRYrQvHlz9uzZQ0JCQppj3LRpE6VKlcLDw4PHjx+rR/LQngMHDqT6vLFjxxIfH893332X6nlFUdiyZQtNmzZFURS9tn19fQkLC+PMmTNpjvNtxo8fz969e/UOBweHTGsfoGTJktjZ2VGsWDH69u1L8eLF2bFjBxYWFmzatAlbW1s+/fRTvXutVKkSVlZWKV7HYsWK4evrm6brpvd7o3bt2nh6eqbaVs+ePfUmlXt7e6MoCj179lTLdDodlStX5saNG3rPNTc3V79++vQpYWFh1KxZM9X/Rx8fH73J7+XKlcPGxkZtMzExke3bt9O0aVMqV66c4vnJMW7atImaNWuSN29evdfVx8eHhISEFEP+hBAiq8jwJyGEwdjZ2eHj48P69euJiooiISHhtZOJb926hZOTE9bW1nrlpUqVUs+/qkSJEinacHd3JyoqikePHqX5DfXVq1e5ePEidnZ2qZ5/+PBhquWurq507tyZpUuXMmrUqBTnHz16xLNnz1i6dClLly5NV9sZUbZsWb1VnrLCli1bsLGxwdjYmMKFC+u9ab569SphYWEULFgw1ef++16LFSuW5uum93vjTW0XKVJE77GtrS0Azs7OKcr/PRfkl19+4dtvvyUoKEhvvk1qK1/9+zoAefPmVdt89OgR4eHhbx2qd/XqVc6dO5fu708hhMhsklQIIQzqs88+o3fv3ty/f5+GDRtm6so+mSExMZGyZcsye/bsVM//+83mq8aMGcPatWuZPn16ik3akifRfv7553Tt2jXV55crVy5jQRtIrVq11NWf/i0xMZGCBQuybt26VM//+03xq5/6Z7Y3tf261cBSK1demah95MgRmjVrRq1atVi4cCGOjo4YGxuzcuVK1q9fn+brKK9ZdOB1EhMT+fTTTxkxYkSq593d3dPVnhBCZJQkFUIIg2rZsiV9+/bl999/Z8OGDa+tV7RoUfbt28fz58/1PpG+dOmSev5VV69eTdHGlStXsLCweO2nuqlxc3Pj7Nmz1KtXL917Lbi5ufH555+zZMkSvL299c7Z2dlhbW1NQkLCW3sQMmuPB0Nyc3Nj37591KhRI9MThvR+b2SFLVu2YGZmxp49e/T2PVm5cmWG2rOzs8PGxoY///zzjfXc3NyIiIjI8l4oIYR4G5lTIUQmSF6O8tSpU4YOJcexsrJi0aJFTJgwgaZNm762XqNGjUhISGDBggV65T/88AMajUZdQSpZYGCg3lj227dv87///Y/69euna2+Kdu3acffuXZYtW5biXHR0NJGRkW98/tixY4mLi2PGjBl65TqdjtatW7Nly5ZU3zg+evRI/drS0hJIWjo0p2rXrh0JCQlMnjw5xbn4+Ph3urf0fm9kBZ1Oh0aj0Zuvc/PmzVRXB0sLrVZLixYt+L//+79Uf68k92i0a9eOwMBA9uzZk6LOs2fPiI+Pz9D1ReoWLlyIRqNJ8SGBEEJ6KoQQ74HXDf95VdOmTfnkk08YM2YMN2/exMvLi19//ZX//e9/DB48OMWOz2XKlMHX11dvSVmAiRMnpiu2zp07s3HjRvr168eBAweoUaMGCQkJXLp0iY0bN6p7KbxOcm/F6tWrU5z77rvvOHDgAN7e3vTu3RtPT0+ePHnCmTNn2LdvH0+ePFHbyJMnD4sXL8ba2hpLS0u8vb3TNe/A0GrXrk3fvn2ZNm0aQUFB1K9fH2NjY65evcqmTZuYO3fua+fTvE16vzeyQuPGjZk9ezYNGjTgs88+4+HDh/z4448UL16cc+fOZajNqVOn8uuvv1K7dm11OePQ0FA2bdrE0aNHyZMnD1999RU///wzTZo0oVu3blSqVInIyEjOnz/P5s2buXnz5muHpIn0W7duHS4uLpw4cYJr165RvHhxQ4ckxHtDkgohRI6g1Wr5+eefGT9+PBs2bGDlypW4uLgwc+ZMhg0blqJ+7dq1qVatGhMnTiQkJARPT09WrVqV7nkKWq2W7du388MPP7BmzRq2bduGhYUFrq6ufPnll2kasz527Fj++9//plh1yt7enhMnTjBp0iS2bt3KwoULyZ8/P6VLl2b69OlqPWNjY1avXs3o0aPp168f8fHxrFy5MkclFQCLFy+mUqVKLFmyhK+//hojIyNcXFz4/PPPqVGjRobbTe/3RlaoW7cuy5cv57vvvmPw4MEUK1aM6dOnc/PmzQwnFYUKFeL48eOMGzeOdevWER4eTqFChWjYsCEWFhYAWFhYcOjQIaZOncqmTZtYs2YNNjY2uLu7M3HiRHWiuXh3wcHBBAQEsHXrVvr27cu6dev45ptvDB1WCpGRkWrvphDZynCr2QqRe7y698LrnDlzRmnQoIFibW2tWFpaKnXr1lUCAwP16sTGxioTJkxQihcvrpiamir58uVTatSoofz6669qndDQUKVbt25KoUKFFBMTE8XBwUFp1qxZqnsOCCGEyByTJ09W8ubNq8TExCj9+/dXSpQokaLO06dPlcGDBytFixZVTExMlEKFCimdO3dWHj16pNaJjo5WvvnmG6VEiRKKqamp4uDgoLRs2VLdtyR5b5kDBw7otR0cHJxiD5muXbsqlpaWyrVr15SGDRsqVlZWSvPmzRVFUZTDhw8rbdq0UZydnRUTExOlcOHCyuDBg1Psp6IoinLx4kWlbdu2SoECBRQzMzPF3d1d+frrrxVFUZTffvtNAZStW7emeN66desUQAkICEjvyylyIempECIb/PXXX9SsWRMbGxtGjBiBsbExS5YsoU6dOhw6dEgdnzthwgSmTZtGr169qFq1KuHh4Zw6dYozZ87w6aefAtC6dWv++usvBg4ciIuLCw8fPmTv3r2EhITg4uJiwLsUQojca926dbRq1QoTExM6duzIokWLOHnyJFWqVAEgIiKCmjVrcvHiRXr06EHFihV5/PgxP//8M3fu3KFAgQIkJCTQpEkT9u/fT4cOHfjyyy95/vw5e/fu5c8//8zQUL34+Hh8fX35+OOP+f7779VerE2bNhEVFUX//v3Jnz8/J06cYP78+dy5c4dNmzapzz937hw1a9bE2NiYPn364OLiwvXr1/m///s/pkyZQp06dXB2dmbdunW0bNkyxWvi5uZGtWrV3uGVFbmGobMaIXKDt/VUtGjRQjExMVGuX7+ult27d0+xtrZWatWqpZZ5eXnp7SL9b0+fPlUAZebMmZkXvMiRoqKilNDQ0DceMTExhg5TiFzh1KlTCqDs3btXUZSkHc0LFy6sfPnll2qd8ePHv/YT/eQd0FesWKEAyuzZs19bJ709FYAyatSoFO2l1iMxbdo0RaPRKLdu3VLLatWqpVhbW+uVvRqPoijK6NGjFVNTU+XZs2dq2cOHDxUjIyPlm2++SXEd8WGS1Z+EyGIJCQn8+uuvtGjRAldXV7Xc0dGRzz77jKNHjxIeHg5Anjx5+Ouvv1JdDhWS1tc3MTHh4MGDKTbeEh+WDRs24Ojo+MYjICDA0GEKkSusW7cOe3t7PvnkEyBpmef27dvj7++vzpXasmULXl5eKT7NT66fXKdAgQIMHDjwtXUyon///inKXl26OTIyksePH1O9enUUReGPP/4AklaZO3z4MD169EixIeOr8XTp0oWYmBg2b96slm3YsIH4+Hg+//zzDMctchcZ/iREFnv06BFRUVGULFkyxblSpUqRmJjI7du3KV26NJMmTaJ58+a4u7tTpkwZGjRoQOfOndXJxaampkyfPp1hw4Zhb2/PRx99RJMmTejSpUuad4gWuYOvry979+59Yx0vL69sikaI3CshIQF/f38++eQTgoOD1XJvb29mzZrF/v37qV+/PtevX6d169ZvbOv69euULFkSI6PMe/tlZGRE4cKFU5SHhIQwfvx4fv755xQfQoWFhQFw48YNgLfu3O7h4UGVKlVYt24dPXv2BJISrY8++khWwBIqSSqEeI/UqlWL69ev87///Y9ff/2V//znP/zwww8sXryYXr16ATB48GCaNm3K9u3b2bNnD+PGjWPatGn89ttvVKhQwcB3ILJLcm+EECJr/fbbb4SGhuLv74+/v3+K8+vWraN+/fqZdr3X9Vj8e/W4ZKampmi12hR1P/30U548ecLIkSPx8PDA0tKSu3fv0q1bNxITE9MdV5cuXfjyyy+5c+cOMTEx/P777yn2hhEfNkkqhMhidnZ2WFhYcPny5RTnLl26hFarxdnZWS3Lly8f3bt3p3v37kRERFCrVi0mTJigJhWQtG/BsGHDGDZsGFevXqV8+fLMmjWL//73v9lyT0II8aFYt24dBQsW5Mcff0xxbuvWrWzbto3Fixfj5uaWph3Qjx8/TlxcHMbGxqnWyZs3L5Bys8tbt26lOebz589z5coVVq9eTZcuXdTyf/duJg/JfVvcAB06dGDo0KH89NNPREdHY2xsTPv27dMck8j9ZE6FEFlMp9NRv359/ve//3Hz5k21/MGDB6xfv56PP/4YGxsbAP7++2+951pZWVG8eHFiYmIAiIqK4sWLF3p13NzcsLa2VusIIYTIHNHR0WzdupUmTZrQpk2bFIefnx/Pnz/n559/pnXr1pw9e5Zt27alaEd5uQN669atefz4caqf8CfXKVq0KDqdjsOHD+udT97AMy10Op1em8lfz507V6+enZ0dtWrVYsWKFYSEhKQaT7ICBQrQsGFD/vvf/7Ju3ToaNGggGysKPdJTIUQmWrFiBbt3705RPmHCBPbu3cvHH3/MF198gZGREUuWLCEmJoYZM2ao9Tw9PalTpw6VKlUiX758nDp1is2bN+Pn5wfAlStXqFevHu3atcPT0xMjIyO2bdvGgwcP6NChQ7bdpxBCfAh+/vlnnj9/TrNmzVI9/9FHH2FnZ8e6detYv349mzdvpm3btvTo0YNKlSrx5MkTfv75ZxYvXoyXlxddunRhzZo1DB06lBMnTlCzZk0iIyPZt28fX3zxBc2bN8fW1pa2bdsyf/58NBoNbm5u/PLLLzx8+DDNcXt4eODm5sbw4cO5e/cuNjY2bNmyJdUFPubNm8fHH39MxYoV6dOnD8WKFePmzZvs2LGDoKAgvbpdunShTZs2AEyePDntL6T4MBhy6SkhcovkJWVfd9y+fVs5c+aM4uvrq1hZWSkWFhbKJ598kmLDoG+//VapWrWqkidPHsXc3Fzx8PBQpkyZosTGxiqKoiiPHz9WBgwYoHh4eCiWlpaKra2t4u3trWzcuNEQty2EELla06ZNFTMzMyUyMvK1dbp166YYGxsrjx8/Vv7++2/Fz89P3Zy0cOHCSteuXZXHjx+r9aOiopQxY8YoxYoVU4yNjRUHBwelTZs2ekuOP3r0SGndurViYWGh5M2bV+nbt6/y559/vnbzu9RcuHBB8fHxUaysrJQCBQoovXv3Vs6ePZuiDUVRlD///FNp2bKlkidPHsXMzEwpWbKkMm7cuBRtxsTEKHnz5lVsbW2V6OjoNL6K4kOhUZR/9W8JIYQQQgjxL/Hx8Tg5OdG0aVOWL19u6HDEe0bmVAghhBBCiLfavn07jx490pv8LUQy6akQQgghhBCvdfz4cc6dO8fkyZMpUKAAZ86cMXRI4j0kPRVCCCEM7vDhwzRt2hQnJyc0Gg3bt2/XO68oCuPHj8fR0RFzc3N8fHxS7Dz/5MkTOnXqhI2NDXny5KFnz55ERESo52/evEmtWrWwtLSkVq1aequxATRp0oQtW7Zk1S0KkWMtWrSI/v37U7BgQdasWWPocMR7SpIKIYQQBhcZGYmXl1eqewEAzJgxg3nz5rF48WKOHz+OpaUlvr6+ekssd+rUib/++ou9e/fyyy+/cPjwYfr06aOeHzZsGIUKFSIoKAhHR0eGDx+untuwYQNarfatOyIL8SFatWoV8fHxnDp16q27b4sPlwx/EkII8V7RaDRs27aNFi1aAEm9FE5OTgwbNkxNBMLCwrC3t2fVqlV06NCBixcv4unpycmTJ6lcuTIAu3fvplGjRty5cwcnJyc8PT2ZPXs2DRo0YNeuXQwfPpy//vqLZ8+eUaVKFX777Te9jSiFEEKknexTkYrExETu3buHtbU1Go3G0OEIIUSmUhSF58+f4+TkhFb7/ndYBwcHc//+fXx8fNQyW1tbvL29CQwMpEOHDgQGBpInTx41oQDw8fFBq9Vy/PhxWrZsiZeXF/v27aN+/fr8+uuvlCtXDoCvvvqKAQMGpDmhiImJ0dtsMjExkSdPnpA/f375myGEyHXS+jdDkopU3Lt3Tz6tEkLkerdv36Zw4cKGDuOt7t+/D4C9vb1eub29vXru/v37FCxYUO+8kZER+fLlU+t8//339O3bFxcXF8qVK8eSJUs4fPgwQUFBTJ8+nXbt2nHq1Cnq16/PvHnzMDExSTWeadOmMXHixMy+TSGEeK+97W+GJBWpsLa2BpJePBsbGwNHI4QQmSs8PBxnZ2f1d92HolChQvzyyy/q45iYGHx9fVm9ejXffvst1tbWXL58mQYNGrBkyRIGDhyYajujR49m6NCh6uOwsDCKFCkifzOEELlSWv9mSFKRiuTuaxsbG/kDIYTItXLKUB0HBwcAHjx4gKOjo1r+4MEDypcvr9Z5+PCh3vPi4+N58uSJ+vx/mzp1KvXr16dSpUr07t2bb7/9FmNjY1q1asVvv/322qTC1NQUU1PTFOXyN0MIkZu97W/G+z+YVgghxAetWLFiODg4sH//frUsPDyc48ePU61aNQCqVavGs2fPOH36tFrnt99+IzExEW9v7xRtXrx4kfXr1zN58mQAEhISiIuLAyAuLo6EhISsvCUhhMh1pKdCCCGEwUVERHDt2jX1cXBwMEFBQeTLl48iRYowePBgvv32W0qUKEGxYsUYN24cTk5O6gpRpUqVokGDBvTu3ZvFixcTFxeHn58fHTp0wMnJSe9aiqLQp08ffvjhBywtLQGoUaMGy5Ytw93dnTVr1tCxY8dsu3chhMgNpKdCCCGEwZ06dYoKFSpQoUIFAIYOHUqFChUYP348ACNGjGDgwIH06dOHKlWqEBERwe7duzEzM1PbWLduHR4eHtSrV49GjRrx8ccfs3Tp0hTXWrp0Kfb29jRp0kQtmzBhAi9evMDb25vixYszYMCALL5jIYTIXWSfilSEh4dja2tLWFiYjI8VehITE4mNjTV0GEK8kbGxMTqd7rXn5Xdc5pLXUwiRm6X1d5wMfxIijWJjYwkODiYxMdHQoQjxVnny5MHBwSHHTMYWQgiRs0lSIUQaKIpCaGgoOp0OZ2fnHLFhmPgwKYpCVFSUuhLSq6slCSGEEFlFkgoh0iA+Pp6oqCicnJywsLAwdDhCvJG5uTkADx8+pGDBgm8cCiWEEEJkBvm4VYg0SF5e8nU77ArxvklOfpOXSRVCCCGykiQVQqSDjE8XOYV8rwohhMhOMvwpMwUfhoiH4FITrO0NHY0QQgghhBDZQnoqMtPur2FLT3hw3tCRCCGEEEIIkW0kqchMJi8n8MZGGTYOIV5j1qxZFC5cGCMjI27evGnocNJEq9ViZ2eXoc3IunXrpu64LIQQQoisI0lFZjJ+mVTESVIh3j/R0dGMGjWKLl26EBwcjLOzs6FDSpPbt28zc+ZMFi5cyJkzZwwdjhBCCCFSIUlFZjKxTPo3NtKwcQiRikePHhEfH0+rVq1wdnbOMcuMFipUiE6dOgFw9+5dA0cjhBBCiNRIUpGZkpMK6anI9RRFISo23iCHoigZijl5J3AjI/31GVxcXJg6dSo9evTA2tqaIkWKsHTpUr06I0eOxN3dHQsLC1xdXRk3bpzeUqUTJkygfPnyrFixgiJFimBlZcUXX3xBQkICM2bMwMHBgYIFCzJlyhS9dp89e0avXr2ws7PDxsaGunXrcvbs2RSxGxsbA/8s7ZtRMTExDBo0iIIFC2JmZsbHH3/MyZMn1fNPnz6lU6dO2NnZYW5uTokSJVi5ciWQtKO6n58fjo6OmJmZUbRoUaZNm/ZO8QghhBC5haz+lJmShz9JT0WuFx2XgOf4PQa59oVJvliYpP9H98WLF8A/b9BfNWvWLCZPnszXX3/N5s2b6d+/P7Vr16ZkyZIAWFtbs2rVKpycnDh//jy9e/fG2tqaESNGqG1cv36dXbt2sXv3bq5fv06bNm24ceMG7u7uHDp0iICAAHr06IGPjw/e3t4AtG3bFnNzc3bt2oWtrS1LliyhXr16XLlyhXz58unFaGRkRExMTLrv+1UjRoxgy5YtrF69mqJFizJjxgx8fX25du0a+fLlY9y4cVy4cIFdu3ZRoEABrl27RnR0NADz5s3j559/ZuPGjRQpUoTbt29z+/btd4pHCCGEyC0kqchMMvxJvKcSEhLw9/fH3NycokWLpjjfqFEjvvjiCyCpV+KHH37gwIEDalIxduxYta6LiwvDhw/H399fL6lITExkxYoVWFtb4+npySeffMLly5fZuXMnWq2WkiVLMn36dA4cOIC3tzdHjx7lxIkTPHz4EFNTUwC+//57tm/fzubNm+nTp49ejO7u7mzbto0WLVqo9dMjMjKSRYsWsWrVKho2bAjAsmXL2Lt3L8uXL+err74iJCSEChUqULlyZfVek4WEhFCiRAk+/vhjNBpNqq+jEEII8aGSpCIzyUTtD4a5sY4Lk3wNdu30OHLkCHXr1kWj0bBq1SqsrKxS1ClXrpz6tUajwcHBgYcPH6plGzZsYN68eVy/fp2IiAji4+OxsbHRa8PFxQVra2v1sb29PTqdDq1Wq1eW3O7Zs2eJiIggf/78eu1ER0dz/fr1FDEuX76cRo0aYWFhwZo1a9R5Fml1/fp14uLiqFGjhlpmbGxM1apVuXjxIgD9+/endevWnDlzhvr169OiRQuqV68OJK0k9emnn1KyZEkaNGhAkyZNqF+/frpiEEIIIXIrSSoykywp+8HQaDQZGoJkCJUrV+b06dPMnDmT4cOH06ZNG0xMTPTq/HtIlEajUedgBAYG0qlTJyZOnIivry+2trb4+/sza9ast7bxpnYjIiJwdHTk4MGDKWLOkydPirJRo0ZRpkwZZs+erfagZLaGDRty69Ytdu7cyd69e6lXrx4DBgzg+++/p2LFigQHB7Nr1y727dtHu3bt8PHxYfPmzVkSixBCCJGTyETtzGTy8hPgOBn+JN4f5ubmlCtXjhEjRhAaGsqNGzfS9fyAgACKFi3KmDFjqFy5MiVKlODWrVvvHFfFihW5f/8+RkZGFC9eXO8oUKBAivqBgYH06dOHypUr6/WIpJWbmxsmJiYcO3ZMLYuLi+PkyZN4enqqZXZ2dnTt2pX//ve/zJkzR2/Suo2NDe3bt2fZsmVs2LCBLVu28OTJk3THIoQQQuQ2OeOj1pxCJmqL91jyG/HkCdtpVaJECUJCQvD396dKlSrs2LGDbdu2vXM8Pj4+VKtWjRYtWjBjxgzc3d25d+8eO3bsoGXLluq8hmSxsbGpDt1KK0tLS/r3789XX31Fvnz5KFKkCDNmzCAqKoqePXsCMH78eCpVqkTp0qWJiYnhl19+oVSpUgDMnj0bR0dHKlSogFarZdOmTTg4OKTaqyKEEEJ8aCSpyEwy/Em8x5L3pUgefpRWzZo1Y8iQIfj5+RETE0Pjxo0ZN24cEyZMeKd4NBoNO3fuZMyYMXTv3p1Hjx7h4OBArVq1sLe316ubvJTsu+6t8d1335GYmEjnzp15/vw5lStXZs+ePeTNmxcAExMTRo8ezc2bNzE3N6dmzZr4+/sDSUnZjBkzuHr1KjqdjipVqqiT0IUQQogPnUbJ6KL3uVh4eDi2traEhYWlmIz6Rld+hfVtwdEL+h7OugBFtnvx4gXBwcEUK1YMMzMzQ4eTITExMZibmzN//nwGDBhg6HDS5fDhw9SuXZuTJ0+m6MEQqXvT92yGf8eJVMnrKYTIzdL6O04+YstM0lMh3mOmpqYMGjSIQYMGYWpqSkhIiKFDShNzc3Nq166Nr68vFStWNHQ4QgghhEiFJBWZaOj2awDERD83cCRCpG7OnDmEhYVx6dIlnJycDB1Omvz11188efKE3bt3pxhqZGVl9drjyJEjBopYCCGE+PDInIpMFE3Shlxa2adCvMeS33TnFK6urq89FxQU9NpzhQoVyoJohBBCCJEaSSoyUYJR0vAnXXy0gSMR4sNQvHhxQ4cghBBCCAw8/Onw4cM0bdoUJycnNBoN27dvf+tzDh48SMWKFTE1NaV48eKsWrVK7/yECRPQaDR6h4eHR9bcwL8kGJkDoFXiICEuW64phBBCCCGEoRk0qYiMjMTLy4sff/wxTfWDg4Np3Lgxn3zyCUFBQQwePJhevXqxZ88evXqlS5cmNDRUPY4ePZoV4aegJO9TAbJXhRBCCCGE+GAYdPhTw4YNadiwYZrrL168mGLFijFr1iwASpUqxdGjR/nhhx/w9fVV6xkZGeHg4JDmdmNiYoiJiVEfh4eHp/m5r9LqTIhTdBhrEiAuCszzZKgdIYQQQgghcpIctfpTYGAgPj4+emW+vr4EBgbqlV29ehUnJydcXV3p1KnTW5fOnDZtGra2turh7OycofiMjXTqZG3pqRBCCCGEEB+KHJVU3L9/P8VOu/b29oSHhxMdnTQ52tvbm1WrVrF7924WLVpEcHAwNWvW5Pnz1y/zOnr0aMLCwtTj9u3bGYrPWKclSpIKIYQQQgjxgclRSUVaNGzYkLZt21KuXDl8fX3ZuXMnz549Y+PGja99jqmpKTY2NnpHRhjrtEQpL5MKWVZW5AJ16tRh8ODB6mMXFxfmzJnzxuekddGFt8msdtIqLfcmhBBCiNTlqKTCwcGBBw8e6JU9ePAAGxsbzM3NU31Onjx5cHd359q1a1ken4mR5pXhT5JUCMNq2rQpDRo0SPXckSNH0Gg0nDt3Ll1tnjx5kj59+mRGeKoJEyZQvnz5FOWhoaHpmnMlhBBCCMPJUUlFtWrV2L9/v17Z3r17qVat2mufExERwfXr13F0dMzq8DDWaYnELOlBnAx/EobVs2dP9u7dy507d1KcW7lyJZUrV6ZcuXLpatPOzg4LC4u3V8wEDg4OmJqaZsu1hBBCCPFuDJpUREREEBQUpO6KGxwcTFBQkDqxevTo0XTp0kWt369fP27cuMGIESO4dOkSCxcuZOPGjQwZMkStM3z4cA4dOsTNmzcJCAigZcuW6HQ6OnbsmOX3Y6zTEq3InIoPgqIk/R8b4lCUNIXYpEkT7OzsUuzlEhERwaZNm2jRogUdO3akUKFCWFhYULZsWX766ac3tvnvIUJXr16lVq1amJmZ4enpyd69e1M8Z+TIkbi7u2NhYYGrqyvjxo0jLi5pH5dVq1YxceJEzp49q+4rkxzvv4c/nT9/nrp162Jubk7+/Pnp06cPERER6vlu3brRokULvv/+exwdHcmfPz8DBgxQr5VeISEhNG/eHCsrK2xsbGjXrp1eT+nZs2f55JNPsLa2xsbGhkqVKnHq1CkAbt26RdOmTcmbNy+WlpaULl2anTt3ZigOIYQQIicw6JKyp06d4pNPPlEfDx06FICuXbuyatUqQkND9VZuKlasGDt27GDIkCHMnTuXwoUL85///EdvOdk7d+7QsWNH/v77b+zs7Pj444/5/fffsbOzy/L7kYnaH5C4KJjqZJhrf30PTCzfWs3IyIguXbqwatUqxowZg0ajAWDTpk0kJCTw+eefs2nTJkaOHImNjQ07duygc+fOuLm5UbVq1be2n5iYSKtWrbC3t+f48eOEhYXpzb9IZm1tzapVq3BycuL8+fP07t0ba2trRowYQfv27fnzzz/ZvXs3+/btA8DW1jZFG5GRkfj6+lKtWjVOnjzJw4cP6dWrF35+fnpJ04EDB3B0dOTAgQNcu3aN9u3bU758eXr37v3W+/n3vSUnFIcOHSI+Pp4BAwbQvn17Dh48CECnTp2oUKECixYtQqfTERQUhLGxMQADBgwgNjaWw4cPY2lpyYULF7CyskpXDEIIIUROYtCkok6dOihv+NT135+wJj/njz/+eO1z/P39MyO0DDHRaf5JKmSitngP9OjRg5kzZ3Lo0CHq1KkDJA19at26NUWLFmX48OFq3YEDB7Jnzx42btyYpqRi3759XLp0iT179uDklJRgTZ06NcU8iLFjx6pfu7i4MHz4cPz9/RkxYgTm5uZYWVm9dW+Z9evX8+LFC9asWYOlZVJCtWDBApo2bcr06dPVVeHy5s3LggUL0Ol0eHh40LhxY/bv35/upGL//v2cP3+e4OBgdYnpNWvWULp0aU6ePEmVKlUICQnhq6++wsPDA4ASJUqozw8JCaF169aULVsWAFdX13RdXwghhMhpDJpU5Db6w58kqcjVjC2SegwMde008vDwoHr16qxYsYI6depw7do1jhw5wqRJk0hISGDq1Kls3LiRu3fvEhsbS0xMTJrnTFy8eBFnZ2c1oQBSnd+0YcMG5s2bx/Xr14mIiCA+Pj7dK6xdvHgRLy8vNaEAqFGjBomJiVy+fFlNKkqXLo1Op1PrODo6cv78+XRdK/l6zs7OenvWeHp6kidPHi5evEiVKlUYOnQovXr1Yu3atfj4+NC2bVvc3NwAGDRoEP379+fXX3/Fx8eH1q1bp3v+ihBCCJGT5KiJ2u87YyOZqP3B0GiShiAZ4ng5jCmtevbsyZYtW3j+/DkrV67Ezc2N2rVrM3PmTObOncvIkSM5cOAAQUFB+Pr6Ehsbm2kvU2BgIJ06daJRo0b88ssv/PHHH4wZMyZTr/Gq5OFHyTQaDYmJiVlyrQkTJvDXX3/RuHFjfvvtNzw9Pdm2bRsAvXr14saNG3Tu3Jnz589TuXJl5s+fnyVxCCGEEO8DSSoykYlOKztqi/dOu3bt0Gq1rF+/njVr1tCjRw80Gg3Hjh2jefPmfP7553h5eeHq6sqVK1fS3G6pUqW4ffs2oaGhatnvv/+uVycgIICiRYsyZswYKleuTIkSJbh165ZeHRMTExISEt56rbNnzxIZ+c/P1bFjx9BqtZQsWTLNMadV8r29uhHmhQsXePbsGZ6enmqZu7s7Q4YM4ddff6VVq1asXLlSPefs7Ey/fv3YunUrw4YNY9myZZkepxBCCPG+kKQiExkbvbL5nQx/Eu8JKysr2rdvz+jRowkNDaVbt25A0hyAvXv3EhAQwMWLF+nbt2+KfWDexMfHB3d3d7p27crZs2c5cuQIY8aM0atTokQJQkJC8Pf35/r168ybN0/9ND+Zi4uLuvLb48ePiYmJSXGtTp06YWZmRteuXfnzzz85cOAAAwcOpHPnzurQp8zk4+ND2bJl6dSpE2fOnOHEiRN06dKF2rVrU7lyZaKjo/Hz8+PgwYPcunWLY8eOcfLkSUqVKgXA4MGD2bNnD8HBwZw5c4YDBw6o54QQQojcSJKKTJQ0UVuGP4n3T8+ePXn69Cm+vr7qHIixY8dSsWJFfH19qVOnDg4ODrRo0SLNbWq1WrZt20Z0dDRVq1alV69eTJkyRa9Os2bNGDJkCH5+fpQvX56AgADGjRunV6d169Y0aNCATz75BDs7u1SXtbWwsGDPnj08efKEKlWq0KZNG+rVq8eCBQvS/2KkgUaj4X//+x958+alVq1a+Pj44OrqyoYNGwDQ6XT8/fffdOnSBXd3d9q1a0fDhg2ZOHEiAAkJCQwYMIBSpUrRoEED3N3dWbhwYZbEKoQQQrwPNMqbll/6QIWHh2Nra0tYWFi6JpRuPXOHY5vnM8tkMbjVg85bszBKkZ1evHhBcHAwxYoVw8zMzNDhCPFWb/qezejvOJE6eT2FELlZWn/HSU9FJtLfUVuGPwkhhBBCiA+DJBWZyFhvonbEmysLIbLNkSNHsLKyeu0hhBBCiHcj+1RkIhMjjUzUFuI9VLlyZYKCggwdhhBCCJFrSVKRiYx1WtlRW4j3kLm5OcWLFzd0GEIIIUSuJcOfMpH+8CdJKoQQQgghxIdBkopMZKzTEqm8sqSsLKwlhBBCCCE+AJJUZCK9HbUT4yEh1rABCSGEEEIIkQ0kqchExkaaf+ZUAMTKBnhCCCGEECL3k6QiE5notMRjRBy6pAKZrC2EEEIIIT4AklRkImNd0ssZlTyvQiZri1ygTp06DB48WH3s4uLCnDlz3vgcjUbD9u3b3/namdWOoRw8eBCNRsOzZ88MHYoQQgiRpSSpyEQmRi+TCnVZWRn+JAynadOmNGjQINVzR44cQaPRcO7cuXS3e/LkSfr06fOu4emZMGEC5cuXT1EeGhpKw4YNM/Va/7Zq1So0Gk2K4z//+U+q5a8eEyZMyNLYxD8SEhIYN24cxYoVw9zcHDc3NyZPnozyyoIYiqIwfvx4HB0dMTc3x8fHh6tXr6rnY2Ji6Ny5MzY2Nri7u7Nv3z69a8ycOZOBAwdm2z0JIURuIvtUZKJ/eipMQYP0VAiD6tmzJ61bt+bOnTsULlxY79zKlSupXLky5cqVS3e7dnZ2mRXiWzk4OGTLdWxsbLh8+bJema2tLU2aNFEfb9iwgfHjx+vVk924s8/06dNZtGgRq1evpnTp0pw6dYru3btja2vLoEGDAJgxYwbz5s1j9erVFCtWjHHjxuHr68uFCxcwMzNj6dKlnD59msDAQHbt2sVnn33GgwcP0Gg0BAcHs2zZMk6dOmXgOxVCiJxJeioykbFOA7zSUyETtXMtRVGIiosyyKGkcaniJk2aYGdnx6pVq/TKIyIi2LRpEz179uTvv/+mY8eOFCpUCAsLC8qWLctPP/30xnb/Pfzp6tWr1KpVCzMzMzw9Pdm7d2+K54wcORJ3d3csLCxwdXVl3LhxxMXFAUk9BRMnTuTs2bNqD0ByzP8e/nT+/Hnq1q2Lubk5+fPnp0+fPkRERKjnu3XrRosWLfj+++9xdHQkf/78DBgwQL3W62g0GhwcHPQOc3Nzvce2trYp6mUkqdiyZQulS5fG1NQUFxcXZs2apXd+4cKFlChRAjMzM+zt7WnTpo16bvPmzZQtW1a9fx8fHyIjP4zfMwEBATRv3pzGjRvj4uJCmzZtqF+/PidOnACSfibnzJnD2LFjad68OeXKlWPNmjXcu3dP/R66ePEizZo1o3Tp0gwYMIBHjx7x+PFjAPr378/06dOxsbF5aywxMTGEh4frHUII8aGTnopMpPZU8MpeFSJXio6Pxnu9t0Guffyz41gYW7y1npGREV26dGHVqlWMGTMGjSYp6d20aRMJCQl07NiRiIgIKlWqxMiRI7GxsWHHjh107twZNzc3qlat+tZrJCYm0qpVK+zt7Tl+/DhhYWF68y+SWVtbs2rVKpycnDh//jy9e/fG2tqaESNG0L59e/788092796tDkextbVN0UZkZCS+vr5Uq1aNkydP8vDhQ3r16oWfn59e4nTgwAEcHR05cOAA165do3379pQvX57evXu/9X6y2unTp2nXrh0TJkygffv2BAQE8MUXX5A/f366devGqVOnGDRoEGvXrqV69eo8efKEI0eOAElDwTp27MiMGTNo2bIlz58/58iRI2lOMnO66tWrs3TpUq5cuYK7uztnz57l6NGjzJ49G4Dg4GDu37+Pj4+P+hxbW1u8vb0JDAykQ4cOeHl5sXbtWqKjo9mzZw+Ojo4UKFCAdevWYWZmRsuWLdMUy7Rp05g4cWKW3KcQQuRUklRkouSkIlqRXbXF+6FHjx7MnDmTQ4cOUadOHSBp6FPr1q2xtbXF1taW4cOHq/UHDhzInj172LhxY5qSin379nHp0iX27NmDk5MTAFOnTk0xD2Ls2LHq1y4uLgwfPhx/f39GjBiBubk5VlZWGBkZvXG40/r163nx4gVr1qzB0tISgAULFtC0aVOmT5+Ovb09AHnz5mXBggXodDo8PDxo3Lgx+/fvf2NSERYWptfrYGVlxf379996/+k1e/Zs6tWrx7hx4wBwd3fnwoULzJw5k27duhESEoKlpSVNmjTB2tqaokWLUqFCBSApqYiPj6dVq1YULVoUgLJly2Z6jO+rUaNGER4ejoeHBzqdjoSEBKZMmUKnTp0A1P+v5O+DZPb29uq5Hj16cO7cOTw9PSlQoAAbN27k6dOnjB8/noMHDzJ27Fj8/f1xc3NjxYoVFCpUKNVYRo8ezdChQ9XH4eHhODs7Z8VtCyFEjiFJRSbSaTXotBoi1YnaklTkVuZG5hz/7LjBrp1WHh4eVK9enRUrVlCnTh2uXbvGkSNHmDRpEpA0+XXq1Kls3LiRu3fvEhsbS0xMDBYWb+8JgaThJM7OzmpCAVCtWrUU9TZs2MC8efO4fv06ERERxMfHp2mYyb+v5eXlpSYUADVq1CAxMZHLly+rbyZLly6NTqdT6zg6OnL+/Pk3tm1tbc2ZM2fUx1pt1owMvXjxIs2bN9crq1GjBnPmzCEhIYFPP/2UokWL4urqSoMGDWjQoAEtW7bEwsICLy8v6tWrR9myZfH19aV+/fq0adOGvHnzZkms75uNGzeybt061q9fT+nSpQkKCmLw4ME4OTnRtWvXNLVhbGzMjz/+qFfWvXt3Bg0axB9//MH27ds5e/YsM2bMYNCgQWzZsiXVdkxNTTE1NU31nBBCfKhkTkUmM9ZpiE4e/iRzKnItjUaDhbGFQY7kYUxp1bNnT7Zs2cLz589ZuXIlbm5u1K5dG0ha7Wbu3LmMHDmSAwcOEBQUhK+vL7GxmbcbfGBgIJ06daJRo0b88ssv/PHHH4wZMyZTr/EqY2NjvccajYbExMQ3Pker1VK8eHH1cHV1zZLY3iY5ufnpp59wdHRk/PjxeHl58ezZM3Q6HXv37mXXrl14enoyf/58SpYsSXBwsEFizW5fffUVo0aNokOHDpQtW5bOnTszZMgQpk2bBvwzqf/Bgwd6z3vw4MFre8AOHDjAX3/9hZ+fHwcPHqRRo0ZYWlrSrl07Dh48mKX3I4QQuY0kFZnMWKdNWv0JJKkQ74V27dqh1WpZv349a9asoUePHmpicuzYMZo3b87nn3+Ol5cXrq6uXLlyJc1tlypVitu3bxMaGqqW/f7773p1AgICKFq0KGPGjKFy5cqUKFGCW7du6dUxMTEhISHhrdc6e/as3sTkY8eOodVqKVmyZJpjNqRSpUpx7NgxvbJjx47h7u6u9q4YGRnh4+PDjBkzOHfuHDdv3uS3334DkhKkGjVqMHHiRP744w9MTEzYtm1btt+HIURFRaXoQdLpdGrCWKxYMRwcHNi/f796Pjw8nOPHj6fae/bixQsGDBjAkiVL1OFUyRP64+Li3vr9KIQQQp8kFZnMRKd9ZZ8KGf4kDM/Kyor27dszevRoQkND6datm3quRIkS7N27l4CAAC5evEjfvn1TfNL7Jj4+Pri7u9O1a1fOnj3LkSNHGDNmjF6dEiVKEBISgr+/P9evX2fevHkp3gi7uLgQHBxMUFAQjx8/JiYmJsW1OnXqhJmZGV27duXPP//kwIEDDBw4kM6dO6cYR/++GjZsGPv372fy5MlcuXKF1atXs2DBAnVeyy+//MK8efMICgri1q1brFmzhsTEREqWLMnx48eZOnUqp06dIiQkhK1bt/Lo0SNKlSpl4LvKHk2bNmXKlCns2LGDmzdvsm3bNmbPnq1OrtZoNAwePJhvv/2Wn3/+mfPnz9OlSxecnJxo0aJFivYmT55Mo0aN1DkrNWrUYOvWrZw7d44FCxZQo0aN7Lw9IYTI8SSpyGTGOu0rE7Wlp0K8H3r27MnTp0/x9fXVm/8wduxYKlasiK+vL3Xq1MHBwSHVN2Cvo9Vq2bZtG9HR0VStWpVevXoxZcoUvTrNmjVjyJAh+Pn5Ub58eQICAtSJyslat25NgwYN+OSTT7Czs0t1WVsLCwv27NnDkydPqFKlCm3atKFevXosWLAgfS+GAVWsWJGNGzfi7+9PmTJlGD9+PJMmTVITvTx58rB161bq1q1LqVKlWLx4MT/99BOlS5fGxsaGw4cP06hRI9zd3Rk7diyzZs3K8s0B3xfz58+nTZs2fPHFF5QqVYrhw4fTt29fJk+erNYZMWIEAwcOpE+fPlSpUoWIiAh2796NmZmZXlt//vknGzdu1FvBqU2bNjRu3JiaNWty7tw55s6dm233JoQQuYFG+VDWI0yH8PBwbG1tCQsLS/dk0lozDlA/bBNjjddBufbQamkWRSmy04sXLwgODqZYsWIp3qAI8T560/fsu/yOEynJ6ymEyM3S+jtOeioyWdJEbempEEIIIYQQHw6DJhWHDx+madOmODk5pdg593UOHjxIxYoVMTU1pXjx4il2Cwb48ccfcXFxwczMDG9vb3XH1ewgE7WF+HD069cPKyurVI9+/foZOjwhhBAi2xh0n4rIyEi8vLzo0aMHrVq1emv94OBgGjduTL9+/Vi3bh379++nV69eODo64uvrCySthz906FAWL16Mt7c3c+bMwdfXl8uXL1OwYMGsviVMjGSithAfikmTJultHvgqGQYjhBDiQ2LQpKJhw4bpmmS4ePFiihUrxqxZs4Ck5RmPHj3KDz/8oCYVs2fPpnfv3nTv3l19zo4dO1ixYgWjRo3K/Jv4F2Od9pXhT5JUCJGbFSxYMFs+rBBCCCHedzlqTkVgYCA+Pj56Zb6+vgQGBgIQGxvL6dOn9epotVp8fHzUOqmJiYkhPDxc78goY52GSOXlpMg4Gf4khBBCCCFyvxyVVNy/fz/FevT29vaEh4cTHR3N48ePSUhISLXO/fv3X9vutGnTsLW1VQ9nZ+cMxyg9FUIIIYQQ4kOTo5KKrDJ69GjCwsLU4/bt2xluS2/zO5moLYQQQgghPgAGnVORXg4ODil2+33w4AE2NjaYm5uj0+nQ6XSp1nFwcHhtu6amppiammZKjEmrP70y/ElRQKPJlLaFEEIIIYR4H+Wonopq1aqxf/9+vbK9e/dSrVo1AExMTKhUqZJencTERPbv36/WyWrGRq8Mf1ISIT4mW64rhBBCCCGEoRg0qYiIiCAoKIigoCAgacnYoKAgQkJCgKRhSV26dFHr9+vXjxs3bjBixAguXbrEwoUL2bhxI0OGDFHrDB06lGXLlrF69WouXrxI//79iYyMVFeDymrGOs0/w59AlpUVOVqdOnUYPHiw+tjFxYU5c+a88Tlp3XPm5s2baDQa9edfCCGEEDmXQYc/nTp1ik8++UR9PHToUAC6du3KqlWrCA0NVRMMgGLFirFjxw6GDBnC3LlzKVy4MP/5z3/U5WQB2rdvz6NHjxg/fjz379+nfPny7N69O8Xk7axiotOSgI54jQlGSizERoBFvmy5thCvatq0KXFxcezevTvFuSNHjlCrVi3Onj1LuXLl0tzmyZMnsbS0zMwwhRBCCJELGDSpqFOnDoqivPZ8artl16lThz/++OON7fr5+eHn5/eu4WWIiVFS50+81hSjhFgZ/iQMpmfPnrRu3Zo7d+5QuHBhvXMrV66kcuXK6UooAOzs7DIzRCGEEELkEjlqTkVOYKxLTipMkgriXxgwGpFVFEUhMSrKIMebEvFXNWnSBDs7uxTJeUREBJs2baJFixZ07NiRQoUKYWFhQdmyZfnpp5/e2Oa/hz9dvXqVWrVqYWZmhqenJ3v37k3vS6nn0KFDVK1aFVNTUxwdHRk1ahTx8fHq+c2bN1O2bFnMzc3Jnz8/Pj4+REYmrbJ28OBBqlatiqWlJXny5KFGjRrcunXrneIRQgghRNrkqNWfcgI1qdAkJxXSU5EbKdHRXK5YySDXLnnmNBoLi7fWMzIyokuXLqxatYoxY8agebkK2aZNm0hISODzzz9n06ZNjBw5EhsbG3bs2EHnzp1xc3OjatWqb20/MTGRVq1aYW9vz/HjxwkLC9Obf5Fed+/epVGjRnTr1o01a9Zw6dIlevfujZmZGRMmTCA0NJSOHTsyY8YMWrZsyfPnzzly5AiKohAfH0+LFi3o3bs3P/30E7GxsZw4cUK9ZyGEEEJkLUkqMpmJLulNTKz25WTtuGgDRiM+dD169GDmzJkcOnSIOnXqAElDn1q3bk3RokUZPny4WnfgwIHs2bOHjRs3pimp2LdvH5cuXWLPnj04OTkBMHXqVBo2bJihWBcuXIizszMLFixAo9Hg4eHBvXv3GDlyJOPHjyc0NJT4+HhatWpF0aJFAShbtiwAT548ISwsjCZNmuDm5gZAqVKlMhSHEEIIIdJPkopMltxTEYdxUoH0VORKGnNzSp45bbBrp5WHhwfVq1dnxYoV1KlTh2vXrnHkyBEmTZpEQkICU6dOZePGjdy9e5fY2FhiYmKwSEMvCMDFixdxdnZWEwrgnZZuvnjxItWqVdPrXahRowYRERHcuXMHLy8v6tWrR9myZfH19aV+/fq0adOGvHnzki9fPrp164avry+ffvopPj4+tGvXDkdHxwzHI4QQQoi0kzkVmcz45UTtOI3MqcjNNBoNWgsLgxzpHdLTs2dPtmzZwvPnz1m5ciVubm7Url2bmTNnMnfuXEaOHMmBAwcICgrC19eX2NjYLHrV3o1Op2Pv3r3s2rULT09P5s+fT8mSJQkODgaSemACAwOpXr06GzZswN3dnd9//93AUQshhBAfBkkqMllyT0WsJBXiPdGuXTu0Wi3r169nzZo19OjRA41Gw7Fjx2jevDmff/45Xl5euLq6cuXKlTS3W6pUKW7fvk1oaKha9i5v4kuVKkVgYKDeRPRjx45hbW2trl6l0WioUaMGEydO5I8//sDExIRt27ap9StUqMDo0aMJCAigTJkyrF+/PsPxCCGEECLtJKnIZMlzKmKQpEK8H6ysrGjfvj2jR48mNDSUbt26AVCiRAn27t1LQEAAFy9epG/fvjx48CDN7fr4+ODu7k7Xrl05e/YsR44cYcyYMRmO84svvuD27dsMHDiQS5cu8b///Y9vvvmGoUOHotVqOX78OFOnTuXUqVOEhISwdetWHj16RKlSpQgODmb06NEEBgZy69Ytfv31V65evSrzKkTupChJhxBCvEckqchkak+FOqdCkgpheD179uTp06f4+vqqcyDGjh1LxYoV8fX1pU6dOjg4ONCiRYs0t6nVatm2bRvR0dFUrVqVXr16MWXKlAzHWKhQIXbu3MmJEyfw8vKiX79+9OzZk7FjxwJgY2PD4cOHadSoEe7u7owdO5ZZs2bRsGFDLCwsuHTpEq1bt8bd3Z0+ffowYMAA+vbtm+F4hHhvXdgOa1vAk2BDRyKEECqZqJ3JkpOKf3oqZKK2MLxq1aql2N8iX758bN++/Y3PO3jwoN7jmzdv6j12d3fnyJEjemVp3UfDxcUlRd3atWtz4sSJVOuXKlUq1d3BAezt7fWGQQmRa0U9gZ1fQeQjOOsPn4w2dERCCAFIT0WmS56oHSM9FUIIITLbnq+TEgo7D6g51NDRCCGESpKKTJY8p+KF8rKnIk6SCvFhmjp1KlZWVqkeGd3LQogP2tV9cPYnQAPNFoCRqaEjEkIIlQx/ymQmL3sqXiS/tNJTIT5Q/fr1o127dqmeM0/HXhtCCCDmOfwyOOnrj/qDcxWDhiOEEP8mSUUmS55TofZUyJwK8YHKly8f+fLlM3QYQuQO+ydB2G3IUwTqjjV0NEIIkYIMf8pk/yQV0lORG6V1ErIQhpaYmGjoEERmuRUIJ5Ylfd10LphYGjYeIYRIhfRUZLLkpCJKkYnauYmxsTEajYZHjx5hZ2eX7l2thcguiqIQGxvLo0eP0Gq1mJiYGDok8S7iXsDPAwEFKnwObnUNHZEQQqRKkopMZvIyqYhOlKQiN9HpdBQuXJg7d+6kWFZViPeRhYUFRYoUQauVDukc7fBM+PsqWNlD/W8NHY0QQryWJBWZzNgo6RPs6MTk4U8ypyK3sLKyokSJEsTFxRk6FCHeSKfTYWRkJD1qOd3DS3BsTtLXjWeBeV6DhiOEEG8iSUUmSx7+FJkocypyI51Oh06nM3QYQogPwZXdkBifNOSpVFO1+PStp0TFxlO5aD7MTeT3kRDi/SD94pksefhTVMLL4U+yT4UQQoiMeHw16d8i1fSKlx2+QeflJ1hxLNgAQQkhROokqchk0lMhhBAiUzy+kvRv/uJqUUKiQuCNvwGo7pbfEFEJIUSqJKnIZMYvd9T+Z/UnmVMhhBAinRTln6SigLtafDE0nLDoOKxMjShbyNZAwQkhREqSVGQy45c7asfIkrJCCCEyKvIxvHgGaCC/m1occP0xAN7F8mGkkz/hQoj3h/xGymTJcypiSN5RW5IKIYQQ6ZTcS5GnCBibq8XHrr0c+lS8gCGiEkKI15KkIpOpO2ojPRVCCCEyKJWhT7HxiZy8+QSQ+RRCiPePJBWZTKfVoNNqiEHmVAghhMigv68l/ftKUnHuzjOiYhPIZ2lCSXtrAwUmhBCpk6QiCxjrNMQorwx/UhTDBiSEECJnedlTcd/Emdj4ROCfoU/V3PKj1crGhkKI94skFVnAWKf9p6dCSYQE2YFZCCFEOrxMKr7cG0m7JYFExMSrk7Rl6JMQ4n0kO2pnAROdlojkpAKSeiuMTAwXkBBCiJwj7gU8vQXAdcWJx7ef0WPlSYJuPwOguptM0hZCvH8kqcgCej0VIPMqhBBCpN2T64BChMaKx9gAcOLlBG0nWzNc8lsYMDghhEidwYc//fjjj7i4uGBmZoa3tzcnTpx4bd24uDgmTZqEm5sbZmZmeHl5sXv3br06EyZMQKPR6B0eHh5ZfRt6jI00gIZEnWlSgawAJYQQIq1eDn26rjgCGiY2K425sQ6Aam4F0GhkPoUQ4v1j0J6KDRs2MHToUBYvXoy3tzdz5szB19eXy5cvU7BgwRT1x44dy3//+1+WLVuGh4cHe/bsoWXLlgQEBFChQgW1XunSpdm3b5/62Mgoe28zeVnZRJ0p2oQYSSqEEEKk3eOrAFyJd8RIq6FDVWc8HKxZdiSY3rWKGTg4IYRInUF7KmbPnk3v3r3p3r07np6eLF68GAsLC1asWJFq/bVr1/L111/TqFEjXF1d6d+/P40aNWLWrFl69YyMjHBwcFCPAgXePP40JiaG8PBwveNdJG+Al6iVngohhBDp9DKpuKE4UbygFaZGOrxd8/OfrpXxcLAxcHBCCJE6gyUVsbGxnD59Gh8fn3+C0Wrx8fEhMDAw1efExMRgZmamV2Zubs7Ro0f1yq5evYqTkxOurq506tSJkJCQN8Yybdo0bG1t1cPZ2TmDd5UkuaciQR3+JHMqhBBCpNErw588nSSJEELkDAZLKh4/fkxCQgL29vZ65fb29ty/fz/V5/j6+jJ79myuXr1KYmIie/fuZevWrYSGhqp1vL29WbVqFbt372bRokUEBwdTs2ZNnj9//tpYRo8eTVhYmHrcvn37ne7NWJc03jVBeiqEEEKkh6KoPRXXFSc8HSWpEELkDDlq9ae5c+fSu3dvPDw80Gg0uLm50b17d73hUg0bNlS/LleuHN7e3hQtWpSNGzfSs2fPVNs1NTXF1NQ00+JUeyq0L5eRjZOkQgghRBqE34O4SOLRcUuxp7STraEjEkKINDFYT0WBAgXQ6XQ8ePBAr/zBgwc4ODik+hw7Ozu2b99OZGQkt27d4tKlS1hZWeHq6vra6+TJkwd3d3euXbuWqfG/iYlR0ssaLz0VQggh0uPJdQBCEu2Ix0h6KoQQOYbBkgoTExMqVarE/v371bLExET2799PtWrV3vhcMzMzChUqRHx8PFu2bKF58+avrRsREcH169dxdHTMtNjfJnmidnxyT4UkFUIIIdIi/B4A95T8FMpjjq2F8VueIIQQ7weDrv40dOhQli1bxurVq7l48SL9+/cnMjKS7t27A9ClSxdGjx6t1j9+/Dhbt27lxo0bHDlyhAYNGpCYmMiIESPUOsOHD+fQoUPcvHmTgIAAWrZsiU6no2PHjtl2X8nDn+K0MlFbCCEyy927d/n888/Jnz8/5ubmlC1bllOnTqnnFUVh/PjxODo6Ym5ujo+PD1evXlXPx8TE0LlzZ2xsbHB3d9dbehxg5syZDBw4MNvuJ1XhdwG4T36ZpC2EyFEMOqeiffv2PHr0iPHjx3P//n3Kly/P7t271cnbISEhaLX/5D0vXrxg7Nix3LhxAysrKxo1asTatWvJkyePWufOnTt07NiRv//+Gzs7Oz7++GN+//137Ozssu2+jJOHP5HcUxGdbdcWQojc6OnTp9SoUYNPPvmEXbt2YWdnx9WrV8mbN69aZ8aMGcybN4/Vq1dTrFgxxo0bh6+vLxcuXMDMzIylS5dy+vRpAgMD2bVrF5999hkPHjxAo9EQHBzMsmXL9JIUgwhPWnjkvpJXhj4JIXIUg0/U9vPzw8/PL9VzBw8e1Htcu3ZtLly48Mb2/P39Myu0DEte/SlOHf4kPRVCCPEupk+fjrOzMytXrlTLihX7ZyM4RVGYM2cOY8eOVYfErlmzBnt7e7Zv306HDh24ePEizZo1o3Tp0ri6uvLVV1/x+PFj7Ozs6N+/P9OnT8fGxsBv5F8Of7qv5KOW9FQIIXIQgw5/yq2S51TE8XIsrMypEEKId/Lzzz9TuXJl2rZtS8GCBalQoQLLli1TzwcHB3P//n29vY9sbW3x9vZW9z7y8vLi6NGjREdHs2fPHhwdHSlQoADr1q3DzMyMli1bpimWzN4w9VWJL4c/hSr5ZPiTECJHkaQiCyTPqYjVyJwKIYTIDDdu3GDRokWUKFGCPXv20L9/fwYNGsTq1asB1P2N3rT3UY8ePfDy8sLT05MpU6awceNGnj59yvjx45k/fz5jx46lePHi+Pr6cvfu3dfGktkbpr4q4VnSdSNM7CiUxzzT2hVCiKwmSUUW+CepeNlTESdzKoQQ4l0kJiZSsWJFpk6dSoUKFejTpw+9e/dm8eLFaW7D2NiYH3/8keDgYE6ePMnHH3/MsGHDGDRoEH/88Qfbt2/n7NmzfPTRRwwaNOi17WT2hqmq+FiMoh8D4FSkOBqNJnPaFUKIbCBJRRYwNkr6QxCLzKkQQuReLi4uTJo0iZCQkCy/lqOjI56ennplpUqVUq+dvL9RevY+OnDgAH/99Rd+fn4cPHiQRo0aYWlpSbt27VLM6XuVqakpNjY2ekdmUJ6HokEhRjHik4qlMqVNIYTILpJUZIHkORUxMqdCCJGLDR48mK1bt+Lq6sqnn36Kv78/MTFZ8yFKjRo1uHz5sl7ZlStXKFq0KJA0advBwUFv76Pw8HCOHz+e6t5HL168YMCAASxZsgSdTkdCQgJxcXEAxMXFkZCQkCX38SbXbyQtf/uIvPh4pp4ICSHE+0qSiiyQPPzphfRUCCFyscGDBxMUFMSJEycoVaoUAwcOxNHRET8/P86cOZOp1xoyZAi///47U6dO5dq1a6xfv56lS5cyYMAAADQaDYMHD+bbb7/l559/5vz583Tp0gUnJydatGiRor3JkyfTqFEjKlSoACQlLVu3buXcuXMsWLCAGjVqZGr8aXHu5eqGLywcsDAx+OKMQgiRLpJUZIHkpCJGSe6pkDkVQojcq2LFisybN4979+7xzTff8J///IcqVapQvnx5VqxYgaIo73yNKlWqsG3bNn766SfKlCnD5MmTmTNnDp06dVLrjBgxgoEDB9KnTx+qVKlCREQEu3fvxszMTK+tP//8k40bNzJx4kS1rE2bNjRu3JiaNWty7tw55s6d+84xp0diosLtm9cBsCxQJFuvLYQQmUE+CskCJkb/Hv4kPRVCiNwrLi6Obdu2sXLlSvbu3ctHH31Ez549uXPnDl9//TX79u1j/fr173ydJk2a0KRJk9ee12g0TJo0iUmTJr2xnTJlyujttA2g1WpZuHAhCxcufOc4M+J0yFMsYh6CEdg5uRgkBiGEeBeSVGQBk5eb371QZE6FECL3OnPmDCtXruSnn35Cq9XSpUsXfvjhBzw8PNQ6LVu2pEqVKgaMMmf4v7P3qKp5AoBRnsIGjkYIIdJPkooskDz8KVqRngohRO5VpUoVPv30UxYtWkSLFi0wNjZOUadYsWJ06NDBANHlHAmJCjvPh9LsZVKBjZNhAxJCiAyQpCILJCcVUYrsUyGEyL1u3Lihrr70OpaWlqxcuTKbIsqZHoS/4HFELA6mklQIIXIumaidBYxfzql4kSg9FUKI3Ovhw4ccP348Rfnx48c5deqUASLKmZ5ExqIhEQfN06QCSSqEEDmQJBVZIHlORXTiy44gmVMhhMiFBgwYkOpu0nfv3lWXehVv9zQqlgKEY0QCaLRgZW/okIQQIt0kqcgCycOfImWithAiF7tw4QIVK1ZMUV6hQgUuvNxzQbzdk8hY7JPnU1gWBF3KuSlCCPG+k6QiC6hzKhIlqRBC5F6mpqY8ePAgRXloaChGRjJlL62eRsbiKJO0hRA5nCQVWeCfpEKXVCBzKoQQuVD9+vUZPXo0YWFhatmzZ8/4+uuv+fTTTw0YWc7yJCoOB0kqhBA5nHyUlAVMjJLmVEQmvDKnQlFAozFgVEIIkbm+//57atWqRdGiRalQoQIAQUFB2Nvbs3btWgNHl3M8i4qVpEIIkeNJUpEF1DkVCS+HPymJkBAHRiYGjEoIITJXoUKFOHfuHOvWrePs2bOYm5vTvXt3OnbsmOqeFSJ1TyJj8ZKkQgiRw0lSkQWSk4qIhFde3vgXklQIIXIdS0tL+vTpY+gwcrSnUbE4kpxUFDJsMEIIkUGSVGQBE6PkngrdP4Uyr0IIkUtduHCBkJAQYmNj9cqbNWtmoIhylieRcdgn71Fh7WjYYIQQIoMylFTcvn0bjUZD4cKFAThx4gTr16/H09NTPrECTF72VMQmKGBiCgkxsgKUECLXuXHjBi1btuT8+fNoNBoURQFA83L+WEJCgiHDyzGeRsTI6k9CiBwvQ6s/ffbZZxw4cACA+/fv8+mnn3LixAnGjBnDpEmTMjXAnCh5+FNcQiIYmyUVSlIhhMhlvvzyS4oVK8bDhw+xsLDgr7/+4vDhw1SuXJmDBw8aOrwcQVEU4qKfYaF52ZstSYUQIofKUFLx559/UrVqVQA2btxImTJlCAgIYN26daxatSoz48uRjF/uqB2fqKAYSVIhhMidAgMDmTRpEgUKFECr1aLVavn444+ZNm0agwYNMnR4OUJ0XAKm8ZEAKDpTMDY3cERCCJExGUoq4uLiMDU1BWDfvn3quFkPDw9CQ0MzL7ocytjolZdVl/Q6yZwKIURuk5CQgLW1NQAFChTg3r17ABQtWpTLly8bMrQc40lkLBaalx86mVgYNhghhHgHGUoqSpcuzeLFizly5Ah79+6lQYMGANy7d4/8+fNnaoA5UfKcCgDFKDmpkJ4KIUTuUqZMGc6ePQuAt7c3M2bM4NixY0yaNAlXV1cDR5czPI2Mw4KkD500JlYGjkYIITIuQ0nF9OnTWbJkCXXq1KFjx454eXkB8PPPP6vDoj5kxq8kFYm6l8Of4iSpEELkLmPHjiUxMRGASZMmERwcTM2aNdm5cyfz5s0zcHQ5w5Oo2H/mUxhLT4UQIufK0OpPderU4fHjx4SHh5M3b161vE+fPlhYyC9FnVaDVgOJyssxsiA9FUKIXMfX11f9unjx4ly6dIknT56QN29edQUo8WZPI2OxQIY/CSFyvgz1VERHRxMTE6MmFLdu3WLOnDlcvnyZggULZmqAOVXyXhUJklQIIXKhuLg4jIyM+PPPP/XK8+XLJwlFOjyJjFWHPyHDn4QQOViGkormzZuzZs0aAJ49e4a3tzezZs2iRYsWLFq0KF1t/fjjj7i4uGBmZoa3tzcnTpx4bd24uDgmTZqEm5sbZmZmeHl5sXv37ndqM6sUsEpKJmIU46QCmagthMhFjI2NKVKkiOxF8Y6eRcViLsOfhBC5QIaSijNnzlCzZk0ANm/ejL29Pbdu3WLNmjXpGke7YcMGhg4dyjfffMOZM2fw8vLC19eXhw8fplp/7NixLFmyhPnz53PhwgX69etHy5Yt+eOPPzLcZlZxtE2aSxGlJhXR2Xp9IYTIamPGjOHrr7/myZMnhg4lx3oSFYulDH8SQuQCGUoqoqKi1GUEf/31V1q1aoVWq+Wjjz7i1q1baW5n9uzZ9O7dm+7du+Pp6cnixYuxsLBgxYoVqdZfu3YtX3/9NY0aNcLV1ZX+/fvTqFEjZs2aleE2s4qDbdJa45EJL6etSE+FECKXWbBgAYcPH8bJyYmSJUtSsWJFvUO83aurP2FiadhghBDiHWRoonbx4sXZvn07LVu2ZM+ePQwZMgSAhw8fYmNjk6Y2YmNjOX36NKNHj1bLtFotPj4+BAYGpvqcmJgYzMzM9MrMzc05evRohttMbjcm5p83/eHh4Wm6hzdxsEka/hSRoEsqkDkVQohcpkWLFoYOIcd7EhmLhzr8SZIKIUTOlaGkYvz48Xz22WcMGTKEunXrUq1aNSCp16JChQppauPx48ckJCRgb2+vV25vb8+lS5dSfY6vry+zZ8+mVq1auLm5sX//frZu3aqO6c1ImwDTpk1j4sSJaYo7rZJ7KsLikpMK6akQQuQu33zzjaFDyPGeyvAnIUQukaHhT23atCEkJIRTp06xZ88etbxevXr88MMPmRbcv82dO5cSJUrg4eGBiYkJfn5+dO/eHa02Q7ehGj16NGFhYepx+/btd441eU7Fs+SkIk7mVAghhND3JDIWc6SnQgiR82WopwLAwcEBBwcH7ty5A0DhwoXTtfFdgQIF0Ol0PHjwQK/8wYMHODg4pPocOzs7tm/fzosXL/j7779xcnJi1KhR6s6tGWkTwNTUFFNT0zTHnhYOL5OKpzEvEx7pqRBC5DJarfaNy8fKylBvpigKz6LisNDKnAohRM6XoY/4ExMTmTRpEra2thQtWpSiRYuSJ08eJk+erO6u+jYmJiZUqlSJ/fv367W7f/9+dTjV65iZmVGoUCHi4+PZsmULzZs3f+c2M1tyT8WTmJd/cGVOhRAil9m2bRtbt25Vjw0bNjBq1CgcHR1ZunSpocN770XGJhCbkCib3wkhcoUM9VSMGTOG5cuX891331GjRg0Ajh49yoQJE3jx4gVTpkxJUztDhw6la9euVK5cmapVqzJnzhwiIyPp3r07AF26dKFQoUJMmzYNgOPHj3P37l3Kly/P3bt3mTBhAomJiYwYMSLNbWYXOytTtBqIln0qhBC5VPIHOq9q06YNpUuXZsOGDfTs2dMAUeUcTyNjAbDSJv0rw5+EEDlZhpKK1atX85///IdmzZqpZeXKlaNQoUJ88cUXaU4q2rdvz6NHjxg/fjz379+nfPny7N69W51oHRISojdf4sWLF4wdO5YbN25gZWVFo0aNWLt2LXny5Elzm9nFSKeloLUZLyJNkgpknwohxAfio48+ok+fPoYO47335GVSYa2NAQUZ/iSEyNEylFQ8efIEDw+PFOUeHh7p3gTJz88PPz+/VM8dPHhQ73Ht2rW5cOHCO7WZnRxszYiJlJ4KIcSHIzo6mnnz5lGoUCFDh/LeexKV3FMRAwnI8CchRI6WoaTCy8uLBQsWpNg9e8GCBZQrVy5TAssNHGzMiLmbnFTInAohRO6SN29evYnaiqLw/PlzLCws+O9//2vAyHKG5OFPlrL6kxAiF8hQUjFjxgwaN27Mvn371AnQgYGB3L59m507d2ZqgDmZg60Z90ke/iQ9FUKI3OWHH37QSyq0Wi12dnZ4e3uTN29eA0aWMzyNigPATHbUFkLkAhlKKmrXrs2VK1f48ccf1U3lWrVqRZ8+ffj222+pWbNmpgaZUznamnGTlz0Vsk+FECKX6datm6FDyNGSeyrMEl/+fZDhT0KIHCzD+1Q4OTmlmJB99uxZli9fLksJvuRga0aM9FQIIXKplStXYmVlRdu2bfXKN23aRFRUFF27djVQZDnDk6hYNCRirMjwJyFEzvduW1GLN3K0NSdGkTkVQojcadq0aRQoUCBFecGCBZk6daoBIspZnkbGYk7sPwUy/EkIkYNJUpGFHF/pqVCkp0IIkcuEhIRQrFixFOVFixYlJCTEABHlLE8iY7FM3vgODRibGzQeIYR4F5JUZKGCNqa8eDmnQpE5FUKIXKZgwYKcO3cuRfnZs2fJnz+/ASLKWZ5GxWKuSR76ZAGvTHoXQoicJl1zKlq1avXG88+ePXuXWHIdUyMdlhYWSeuPS1IhhMhlOnbsyKBBg7C2tqZWrVoAHDp0iC+//JIOHToYOLr339OoOPLLyk9CiFwiXUmFra3tW8936dLlnQLKbWysbeAZaBJiQFHkkyghRK4xefJkbt68Sb169TAySvpzkpiYSJcuXWRORRoUymOOvUaBWGTlJyFEjpeupGLlypVZFUeuZWtrm5RUoCRN1pYxs0KIXMLExIQNGzbw7bffEhQUhLm5OWXLlqVo0aKGDi1H2D6gBlyPgbXIyk9CiBwvw0vKirTJl8cWbr18EBctSYUQItcpUaIEJUqUMHQYOVNsVNK/MvxJCJHDyUTtLOaQx+qfZWVjIw0bjBBCZKLWrVszffr0FOUzZsxIsXeFeI245KRChj8JIXI2SSqymIONGdHJG+DJZG0hRC5y+PBhGjVqlKK8YcOGHD582AAR5UCxEUn/yvAnIUQOJ0lFFnO0NSMa06QHyZ9ICSFELhAREYGJiUmKcmNjY8LDww0QUQ4kw5+EELmEJBVZzMHWjChFkgohRO5TtmxZNmzYkKLc398fT09PA0SUA8nwJyFELiETtbNYQRszbr0c/hQdFYFM0xZC5Bbjxo2jVatWXL9+nbp16wKwf/9+1q9fz+bNmw0cXQ4hw5+EELmEJBVZzMrUiFiNGQBhYc8kqRBC5BpNmzZl+/btTJ06lc2bN2Nubo6Xlxe//fYb+fLlM3R4OUOs9FQIIXIHGf6UDRKMklKJ8OcyxlgIkbs0btyYY8eOERkZyY0bN2jXrh3Dhw/Hy8vL0KHlDHEyp0IIkTtIUpEdXu5NERnx3MCBCCFE5jt8+DBdu3bFycmJWbNmUbduXX7//XdDh5UzyPAnIUQuIUlFNtC87NaOjpSeCiFE7nD//n2+++47SpQoQdu2bbGxsSEmJobt27fz3XffUaVKlSy9/nfffYdGo2Hw4MFq2YsXLxgwYAD58+fHysqK1q1b8+DBA/X8kydPaNq0KVZWVlSoUIE//vhDr80BAwYwa9asLI07BRn+JITIJSSpyAY606RPoF5EyeZ3Qoicr2nTppQsWZJz584xZ84c7t27x/z587Pt+idPnmTJkiWUK1dOr3zIkCH83//9H5s2beLQoUPcu3ePVq1aqeenTJnC8+fPOXPmDHXq1KF3797qud9//53jx4/rJSnZQoY/CSFyCUkqsoGxWdIfi9gXEQaORAgh3t2uXbvo2bMnEydOpHHjxuh0umy7dkREBJ06dWLZsmXkzZtXLQ8LC2P58uXMnj2bunXrUqlSJVauXElAQIA6FOvixYt06NABd3d3+vTpw8WLFwGIi4ujX79+LF68OE33EhMTQ3h4uN6RYTL8SQiRS0hSkQ1Mza0ASJCkQgiRCxw9epTnz59TqVIlvL29WbBgAY8fP86Waw8YMIDGjRvj4+OjV3769Gni4uL0yj08PChSpAiBgYEA6spU8fHx7NmzR+3pmDFjBnXq1KFy5cppimHatGnY2tqqh7Ozc8ZvSIY/CSFyCUkqsoG5pTUACTGy+Z0QIuf76KOPWLZsGaGhofTt2xd/f3+cnJxITExk7969PH+eNYtS+Pv7c+bMGaZNm5bi3P379zExMSFPnjx65fb29ty/fx+AUaNGYWRkhJubG9u2bWP58uVcvXqV1atXM27cOPr164erqyvt2rUjLCzstXGMHj2asLAw9bh9+3bGb0qGPwkhcglJKrKBxcukgrhoFEUxbDBCCJFJLC0t6dGjB0ePHuX8+fMMGzaM7777joIFC9KsWbNMvdbt27f58ssvWbduHWZmZhlqw9bWlvXr13Pr1i0OHTqEp6cnffv2ZebMmaxbt44bN25w+fJlLCwsmDRp0mvbMTU1xcbGRu/IMBn+JITIJSSpyAZW1rYAmCovCI+ON3A0QgiR+UqWLMmMGTO4c+cOP/30U6a3f/r0aR4+fEjFihUxMjLCyMiIQ4cOMW/ePIyMjLC3tyc2NpZnz57pPe/Bgwc4ODik2ubKlSvJkycPzZs35+DBg7Ro0QJjY2Patm3LwYMHM/0eUiXDn4QQuYTsqJ0NkidqmxPDg+cvsLUwNnBEQgiRNXQ6HS1atKBFixaZ2m69evU4f/68Xln37t3x8PBg5MiRODs7Y2xszP79+2ndujUAly9fJiQkhGrVqqVo79GjR0yaNImjR48CkJCQQFxcHJA0cTshISFT409VfCwkJl1Thj8JIXI6SSqyw8vN78w1MdwPe4G7vbWBAxJCiJzF2tqaMmXK6JVZWlqSP39+tbxnz54MHTqUfPnyYWNjw8CBA6lWrRofffRRivYGDx7MsGHDKFSoEAA1atRg7dq11K9fn6VLl1KjRo2sv6m4V5YZl+FPQogcTpKK7GCc3FMRy83wFwYORgghcqcffvgBrVZL69atiYmJwdfXl4ULF6aot2fPHq5du8batWvVMj8/P06dOoW3tzdVq1blm2++yfqAk4c+aY3AyCTrryeEEFnI4HMqfvzxR1xcXDAzM8Pb25sTJ068sf6cOXMoWbIk5ubmODs7M2TIEF68+OeN+oQJE9BoNHqHh4dHVt/GmyX3VBDDw+cxho1FCCFyiYMHDzJnzhz1sZmZGT/++CNPnjwhMjKSrVu3pjqfwtfXl+PHj6PV/vMn0MLCgo0bNxIeHs6+ffsoWLBg1t+ArPwkhMhFDNpTsWHDBoYOHcrixYvx9vZmzpw5+Pr6cvny5VR/oa9fv55Ro0axYsUKqlevzpUrV+jWrRsajYbZs2er9UqXLs2+ffvUx0ZGBu6QeWX40wPpqRBCCAGy8pMQIlcxaE/F7Nmz6d27N927d8fT05PFixdjYWHBihUrUq0fEBBAjRo1+Oyzz3BxcaF+/fp07NgxRe+GkZERDg4O6lGgQIHsuJ3XM/ln+JMkFUIIIQBZ+UkIkasYLKmIjY3l9OnTerufarVafHx81N1P/6169eqcPn1aTSJu3LjBzp07adSokV69q1ev4uTkhKurK506dSIkJOSNscTExBAeHq53ZKpXhj89CJfhT0IIIZDhT0KIXMVg44IeP35MQkIC9vb2euX29vZcunQp1ed89tlnPH78mI8//hhFUYiPj6dfv358/fXXah1vb29WrVpFyZIlCQ0NZeLEidSsWZM///wTa+vUV12aNm0aEydOzLyb+zfjpE+hzDRxPA6LfEtlIYQQHwQZ/iSEyEUMPlE7PQ4ePMjUqVNZuHAhZ86cYevWrezYsYPJkyerdRo2bEjbtm0pV64cvr6+7Ny5k2fPnrFx48bXtjt69GjCwsLU4/bt25kbuPE/XdvhEREkJsqu2kII8cGT4U9CiFzEYD0VBQoUQKfT8eDBA73yN+1+Om7cODp37kyvXr0AKFu2LJGRkfTp04cxY8boreSRLE+ePLi7u3Pt2rXXxmJqaoqpqek73M1bGJmpXxonvuBJVCwFrLLwekIIId5/ycOfjCWpEELkfAbrqTAxMaFSpUrs379fLUtMTGT//v2p7n4KEBUVlSJx0Ol0AChK6p/+R0REcP36dRwdHTMp8gzQasFIVoASQgjxiuThTyZWho1DCCEygUGHPw0dOpRly5axevVqLl68SP/+/YmMjKR79+4AdOnShdGjR6v1mzZtyqJFi/D39yc4OJi9e/cybtw4mjZtqiYXw4cP59ChQ9y8eZOAgABatmyJTqejY8eOBrlH1cvubXNieSiTtYUQQsjwJyFELmLQDRzat2/Po0ePGD9+PPfv36d8+fLs3r1bnbwdEhKi1zMxduxYNBoNY8eO5e7du9jZ2dG0aVOmTJmi1rlz5w4dO3bk77//xs7Ojo8//pjff/8dOzu7bL8/PcYWwN9Y8EJ6KoQQQsjwJyFErmLgXeHAz88PPz+/VM8dPHhQ77GRkRHffPMN33zzzWvb8/f3z8zwMs/LPxrmmlhZVlYIIQTEvlwNUIY/CSFygRy1+lOO9nKvCjNiePBceiqEEOKDpyYV0lMhhMj5JKnILi97KiyI4aEMfxJCCCHDn4QQuYgkFdnllYnaVx5EkCB7VQghxIdNhj8JIXIRSSqyy8vhT3lN4gl5EsX/nb1n4ICEEEIYlAx/EkLkIpJUZJeX3dufuFoCMGffFeISEg0ZkRBCCEOS4U9CiFxEkors8vKPRpVC5uS3NOHm31FsOX3HwEEJIYQwGBn+JITIRQy+pOwH42VSYZIYTf86bny74yLz9l+lZcVCmBrpDBycEEKIrJaQkEBcXNw/BUa2YOUMGnN4IQt4CPFvxsbG6ubG4v0nSUV2eTmngrhoPq9TlP8cCeZe2As2nLxNl2ouBg1NCCFE1lEUhfv37/Ps2TP9E5XGgpIIYUBEsCFCE+K9lydPHhwcHNBoNIYORbyFJBXZJXkiXlwUZsY6ulZ3YfruSwRc+1uSCiGEyMWSE4qCBQtiYWHxz5ujxKJJSYVWB/KGSQg9iqIQFRXFw4cPAXB0dDRwROJtJKnILskT8WKTJuY55TEDICw67nXPEEIIkcMlJCSoCUX+/PkNHY4QOYq5edIoj4cPH1KwYEEZCvWek4na2eWV4U8AtubGgCQVQgiRmyXPobCwkBWehMiI5J8dvflI4r0kSUV2MU5aSjZ5CcHkpCL8hfyQCCFEbifjwYXIGPnZyTkkqcguak9FUlJhIz0VQgghhBAil5CkIruoE7X1hz89fxFPQqJiqKiEEEIIIYR4Z5JUZBfjf1Z/gn+SCoDnMgRKCCHEe2zWrFkULlwYIyMjbt68aehw0kSr1WJnZ8eAAQMMHYoQHwRJKrJL8vCnl6s/Geu0WJgkrWIQHh1vqKiEEEKIN4qOjmbUqFF06dKF4OBgnJ2dDR1Smty+fZuZM2eycOFCzpw5Y+hwhMj1JKnILupE7Wi1yMZM5lUIIYR4vz169Ij4+HhatWqFs7NzjlnWs1ChQnTq1AmAu3fvGjiadyerH4n3nSQV2UWdqB2pFsmyskII8WFRFIWo2HiDHIqSsfl7iYmJABgZ6W9t5eLiwtSpU+nRowfW1tYUKVKEpUuX6tUZOXIk7u7uWFhY4Orqyrhx4/TeHE+YMIHy5cuzYsUKihQpgpWVFV988QUJCQnMmDEDBwcHChYsyJQpU/TaffbsGb169cLOzg4bGxvq1q3L2bNnU8RubJz0dzYhISFd93zy5Ek+/fRTChQogK2tLbVr107R2/Hs2TP69u2Lvb09ZmZmlClThl9++UU9f+zYMerUqYOFhQV58+bF19eXp0+fqq/dnDlz9NorX748EyZMUB9rNBoWLVpEs2bNsLS0ZMqUKSQkJNCzZ0+KFSuGubk5JUuWZO7cuSniX7FiBaVLl8bU1BRHR0f8/PwA6NGjB02aNNGrGxcXR8GCBVm+fHm6XiMh/k02v8suyUlFYjwkxIHOWJIKIYT4wETHJeA5fo9Brn1hki8WJun/s//ixQvgnzfor5o1axaTJ0/m66+/ZvPmzfTv35/atWtTsmRJAKytrVm1ahVOTk6cP3+e3r17Y21tzYgRI9Q2rl+/zq5du9i9ezfXr1+nTZs23LhxA3d3dw4dOkRAQAA9evTAx8cHb29vANq2bYu5uTm7du3C1taWJUuWUK9ePa5cuUK+fPn0YjQyMiImJiZd9/z8+XO6du3K/PnzURSFWbNm0ahRI65evYq1tTWJiYk0bNiQ58+f89///hc3NzcuXLig9uIEBQVRr149evTowdy5czEyMuLAgQPpTm4mTJjAd999x5w5czAyMiIxMZHChQuzadMm8ufPT0BAAH369MHR0ZF27doBsGjRIoYOHcp3331Hw4YNCQsL49ixYwD06tWLWrVqERoaqu5Q/csvvxAVFUX79u3TFZsQ/yZJRXYxsfzn67go0NliY5708steFUIIId5HCQkJ+Pv7Y25uTtGiRVOcb9SoEV988QWQ1Cvxww8/cODAATWpGDt2rFrXxcWF4cOH4+/vr5dUJCYmsmLFCqytrfH09OSTTz7h8uXL7Ny5E61WS8mSJZk+fToHDhzA29ubo0ePcuLECR4+fIipqSkA33//Pdu3b2fz5s306dNHL0Z3d3e2bdtGixYt1PpvU7duXb3HS5cuJU+ePBw6dIgmTZqwb98+Tpw4wcWLF3F3dwfA1dVVrT9jxgwqV67MwoUL1bLSpUun6dqv+uyzz+jevbte2cSJE9WvixUrRmBgIBs3blSTim+//ZZhw4bx5ZdfqvWqVKkCQPXq1SlZsiRr165V/w9WrlxJ27ZtsbKySnd8QrxKkorsojMBjRaUxKTJ2ma2sleFEEJ8YMyNdVyY5Guwa6fHkSNHqFu3LhqNhlWrVqX6prNcuXLq1xqNBgcHBx4+fKiWbdiwgXnz5nH9+nUiIiKIj4/HxsZGrw0XFxesra3Vx/b29uh0OrRarV5Zcrtnz54lIiKC/Pnz67UTHR3N9evXU8S4fPlyGjVqhIWFBWvWrFHnWbzJgwcPGDt2LAcPHuThw4ckJCQQFRVFSEgIkNQTUbhwYTWh+LegoCDatm371uu8TeXKlVOU/fjjj6xYsYKQkBCio6OJjY2lfPnyADx8+JB79+5Rr16917bZq1cvli5dyogRI3jw4AG7du3it99+e+dYhZCkIrtoNEnLysZGpFhWVpIKIYT4MGg0mgwNQTKEypUrc/r0aWbOnMnw4cNp06YNJiYmenX+PSRKo9GoczACAwPp1KkTEydOxNfXF1tbW/z9/Zk1a9Zb23hTuxERETg6OnLw4MEUMefJkydF2ahRoyhTpgyzZ89We1DepmvXrvz999/MnTuXokWLYmpqSrVq1YiNjQXA3Nz8jc9/23mtVptijktqE7EtLS31Hvv7+zN8+HBmzZpFtWrVsLa2ZubMmRw/fjxN1wXo0qULo0aNIjAwkICAAIoVK0bNmjXf+jwh3iZn/GbLLdSkQn8DPEkqhBBCvG/Mzc0pV64cI0aM4L///S83btzAw8Mjzc8PCAigaNGijBkzRi27devWO8dVsWJF7t+/j5GRES4uLm+tHxgYyPLly1P91P91jh07xsKFC2nUqBGQtDzt48eP1fPlypXjzp07XLlyJdXeinLlyrF//369oUqvsrOzIzQ0VH0cHh5OcHBwmuKqXr26OuQM0Oudsba2xsXFhf379/PJJ5+k2kb+/Plp0aIFK1euJDAwMMXwKiEySlZ/yk7qClBJPRXJS8qGS1IhhBDiPZU8NCl5wnZalShRgpCQEPz9/bl+/Trz5s1j27Zt7xyPj48P1apVo0WLFvz666/cvHmTgIAAxowZw6lTp1LUj42NTfd8gRIlSrB27VouXrzI8ePH6dSpk14vQO3atalVqxatW7dm7969BAcHq5PNAUaPHs3Jkyf54osvOHfuHJcuXWLRokVqYlK3bl3Wrl3LkSNHOH/+PF27dk3TUr0lSpTg1KlT7NmzhytXrjBu3DhOnjypV2fChAnMmjWLefPmcfXqVc6cOcP8+fP16vTq1YvVq1dz8eJFunbtmq7XRojXkaQiO71mV23pqRBCCPG+Sn6zmzz8KK2aNWvGkCFD8PPzo3z58gQEBDBu3Lh3jkej0bBz505q1apF9+7dcXd3p0OHDty6dQt7e3u9usmrLaV3b43ly5fz9OlTKlasSOfOnRk0aBAFCxbUq7NlyxaqVKlCx44d8fT0ZMSIEer13N3d+fXXXzl79ixVq1alWrVq/O9//1OX5R09ejS1a9emSZMmNG7cmBYtWuDm5vbWuPr27UurVq1o37493t7e/P3333q9FpA0dGvOnDksXLiQ0qVL06RJE65evapXx8fHB0dHR3x9fXFyckrXayPE62iUjC5cnYuFh4dja2tLWFhYigll72RZXbh7Gjr6Q8mG7LvwgF5rTuFV2Jb/+X2cedcRQog3yLLfcR+oN72eL168IDg4mGLFimFmZmagCN9NTEwM5ubmzJ8/nwEDBhg6nHQ5fPgwtWvX5uTJk+ka/pTbRUREUKhQIVauXEmrVq0MHc4b5YafoZwurX8zpKciOyX3VMQmbYBna/Fy+NOLeENFJIQQQryRqakpgwYNYtCgQZiamqorIL3vzM3NqV27Nr6+vlSsWNHQ4bwXEhMTefjwIZMnTyZPnjw0a9bM0CGJXEQmamcndfhT0kTt5DkVMvxJCCHE+2zOnDl8++23PHr0KMcMl/nrr7/ImzcvefPmTXHuTXMsdu3alWtXQwoJCaFYsWIULlyYVatWpdglXYh3Id9N2elfE7VfnVOhKAoajcZQkQkhhBBvZGVllaM2SHt1M7p/CwoKeu25QoUKZUE07wcXF5cUS9kKkVkMPvzpxx9/xMXFBTMzM7y9vTlx4sQb68+ZM4eSJUtibm6Os7MzQ4YMSbEiRXrbzDavmaidkKgQGZtgqKiEEEKID0rx4sVfe6RlrwchREoGTSo2bNjA0KFD+eabbzhz5gxeXl74+vrq7cb5qvXr1zNq1Ci++eYbLl68yPLly9mwYQNff/11htvMVib6w5/MjLWY6JL+C2RZWSGEEEIIkVMZNKmYPXs2vXv3pnv37nh6erJ48WIsLCxYsWJFqvUDAgKoUaMGn332GS4uLtSvX5+OHTvq9USkt01IWtkiPDxc78gSycOfXk7U1mg02JgnjUCTeRVCCCGEECKnMlhSERsby+nTp/Hx8fknGK0WHx8fAgMDU31O9erVOX36tJpE3Lhxg507d6o7XmakTYBp06Zha2urHs7Ozplxiyn9a6I2gI3sVSGEEEIIIXI4gyUVjx8/JiEhIcVGNfb29ty/fz/V53z22WdMmjSJjz/+GGNjY9zc3KhTp446/CkjbULSJjRhYWHqcfv27Xe8u9dIJamQDfCEEEIIIUROZ/CJ2ulx8OBBpk6dysKFCzlz5gxbt25lx44dTJ48+Z3aNTU1xcbGRu/IEmpSEakWJScVMqdCCCGEEELkVAZLKgoUKIBOp+PBgwd65Q8ePMDBwSHV54wbN47OnTvTq1cvypYtS8uWLZk6dSrTpk0jMTExQ21mK3VJ2VeGP8leFUIIIXKZOnXqMHjwYPWxi4sLc+bMeeNzNBoN27dvf+drZ1Y7Qoj0MVhSYWJiQqVKldi/f79alpiYyP79+6lWrVqqz4mKikKr1Q9Zp9MBoChKhtrMViavH/4kPRVCCCHeB02bNqVBgwapnjty5AgajYZz586lq82TJ0/Sp0+fzAhPNWHCBMqXL5+iPDQ0lIYNG2bqtYQQb2fQze+GDh1K165dqVy5MlWrVmXOnDlERkbSvXt3ALp06UKhQoWYNm0akPSLbvbs2VSoUAFvb2+uXbvGuHHjaNq0qZpcvK1Ng0oe/hSbcviT9FQIIYR4H/Ts2ZPWrVtz584dChcurHdu5cqVVK5cmXLlyqWrTTs7u8wM8Y3ei5EJBqQoCgkJCbJbtsh2Bp1T0b59e77//nvGjx9P+fLlCQoKYvfu3epE65CQEEJDQ9X6Y8eOZdiwYYwdOxZPT0969uyJr68vS5YsSXObBmVqnfTvizC1SO2peBFviIiEEEJkJ0VJ+mDJEEcad1Ju0qQJdnZ2rFq1Sq88IiKCTZs20aJFCzp27EihQoWwsLCgbNmy/PTTT29s89/Dn65evUqtWrUwMzPD09OTvXv3pnjOyJEjcXd3x8LCAldXV8aNG0dcXNIHcKtWrWLixImcPXsWjUaDRqNR4/338Kfz589Tt25dzM3NyZ8/P3369CEiIkI9361bN1q0aMH333+Po6Mj+fPnZ8CAAeq13mbt2rVUrlwZa2trHBwc+Oyzz1LsjfXXX3/RpEkTbGxssLa2pmbNmly/fl09v2LFCkqXLo2pqSmOjo74+fkBcPPmTTQajd4O4M+ePUOj0XDw4EEgab6pRqNh165dVKpUCVNTU44ePcr169dp3rw59vb2WFlZUaVKFfbt26cXV0xMDCNHjsTZ2RlTU1OKFy/O8uXLURSF4sWL8/333+vVDwoKQqPRcO3atTS9NuLDYvA01s/PT/3h+bfkH5hkRkZGfPPNN3zzzTcZbtOgLF9+UhP1WC2SfSqEECJtpk2bxtatW7l06RLm5uZUr16d6dOnU7JkSbXOixcvGDZsGP7+/sTExODr68vChQvVD5aePHlC165dOXDgACVKlGDFihVUqFBBff6AAQNwdXVl2LBhWXMTcVEw1Slr2n6br++BieVbqxkZGdGlSxdWrVrFmDFj0Gg0AGzatImEhAQ+//xzNm3axMiRI7GxsWHHjh107twZNzc3qlat+tb2ExMTadWqFfb29hw/fpywsDC9+RfJrK2tWbVqFU5OTpw/f57evXtjbW3NiBEjaN++PX/++Se7d+9W3yjb2tqmaCMyMhJfX1+qVavGyZMnefjwIb169cLPz08vaTpw4ACOjo4cOHCAa9eu0b59e8qXL0/v3r3fej9xcXFMnjyZkiVL8vDhQ4YOHUq3bt3YuXMnAHfv3qVWrVrUqVOH3377DRsbG44dO0Z8fNKHiYsWLWLo0KF89913NGzYkLCwMI4dO/bW6/7bqFGj+P7773F1dSVv3rzcvn2bRo0aMWXKFExNTVmzZg1Nmzbl8uXLFClSBEgaERIYGMi8efPw8vIiODiYx48fo9Fo6NGjBytXrmT48OHqNVauXEmtWrUoXrx4uuMTuZ/Bk4oPSnJS8SIM4mPByESGPwkhRBodOnSIAQMGUKVKFeLj4/n666+pX78+Fy5cwNIy6c3ykCFD2LFjB5s2bcLW1hY/Pz9atWqlvkmbMmUKz58/58yZMyxatIjevXtz6tQpAH7//XeOHz/OvHnzDHaP74sePXowc+ZMDh06RJ06dYCkN5StW7emaNGiem80Bw4cyJ49e9i4cWOakop9+/Zx6dIl9uzZg5NTUoI1derUFPMgxo4dq37t4uLC8OHD8ff3Z8SIEZibm2NlZYWRkdEbhzutX7+eFy9esGbNGvV7ZMGCBTRt2pTp06eryWbevHlZsGABOp0ODw8PGjduzP79+9OUVPTo0UP92tXVlXnz5lGlShUiIiKwsrLixx9/xNbWFn9/f4yNk/7mu7u7q8/59ttvGTZsGF9++aVaVqVKlbde998mTZrEp59+qj7Oly8fXl5e6uPJkyezbds2fv75Z/z8/Lhy5QobN25k79696v5erq6uav1u3boxfvx4Tpw4QdWqVYmLi2P9+vUpei+ESCZJRXYyywMaHSgJSb0VNk6y+Z0QQqTR7t279R6vWrWKggULcvr0aWrVqkVYWBjLly9n/fr11K1bF0h6I1yqVCl+//13PvroIy5evEiHDh1wd3enT58+LF26FEj6tLlfv3785z//UefovU5MTAwxMTHq4/Dw8LTfhLFFUo+BISTP60sDDw8PqlevzooVK6hTpw7Xrl3jyJEjTJo0iYSEBKZOncrGjRu5e/cusbGxxMTEYGGRtvYvXryIs7OzmlAAqS6msmHDBubNm8f169eJiIggPj4+3Uu+X7x4ES8vLzWhAKhRowaJiYlcvnxZTSpKly6t9//u6OjI+fPn03SN06dPM2HCBM6ePcvTp09JTEwEkoZwe3p6EhQURM2aNdWE4lUPHz7k3r171KtXL133lZrKlSvrPY6IiGDChAns2LGD0NBQ4uPjiY6OJiQkBEgayqTT6ahdu3aq7Tk5OdG4cWNWrFhB1apV+b//+z9iYmJo27btO8cqcqcctU9FjqfVgmWBpK8jHwH/LCkrqz8JIUT6hIUlzU/Lly8fkPTmLi4uTv3UFZLeHBcpUoTAwEAAvLy8+O2334iPj2fPnj3qhOMZM2ZQp06dFG/MUjNt2jRsbW3Vw9nZOe1BazRJQ5AMcbwcxpRWPXv2ZMuWLTx//pyVK1fi5uZG7dq1mTlzJnPnzmXkyJEcOHCAoKAgfH19iY2NTVf7bxIYGEinTp1o1KgRv/zyC3/88QdjxozJ1Gu86t9v+DUajZocvEny8CobGxvWrVvHyZMn2bZtG4Aaq7m5+Wuf/6ZzgLripfLKfJjXzfV4NXECGD58ONu2bWPq1KkcOXKEoKAgypYtm6a4kvXq1Qt/f3+io6NZuXIl7du3T3PyKD48klRkN4vkpCJpXoUMfxJCiPRLTExk8ODB1KhRgzJlygBw//59TExMyJMnj15de3t77t+/DySNOzcyMsLNzY1t27axfPlyrl69yurVqxk3bhz9+vXD1dWVdu3aqUnLv40ePZqwsDD1uH37dpbeq6G0a9cOrVbL+vXrWbNmDT169ECj0XDs2DGaN2/O559/jpeXF66urly5ciXN7ZYqVYrbt2/rLcTy+++/69UJCAigaNGijBkzhsqVK1OiRAlu3bqlV8fExISEhIS3Xuvs2bNERv6z6uKxY8fQarV6c3Ey6tKlS/z9999899131KxZEw8PjxSTtMuVK8eRI0dSTQasra1xcXHRWwr/VcmrZr36Wr06aftNjh07Rrdu3WjZsiVly5bFwcGBmzdvqufLli1LYmIihw4dem0bjRo1wtLSkkWLFrF79269oV5C/JskFdnN8l9JhUVSUhETn8iLuDf/chRCCJFkwIAB/Pnnn/j7+6freba2tqxfv55bt25x6NAhPD096du3LzNnzmTdunXcuHGDy5cvY2FhwaRJk1Jtw9TUFBsbG70jN7KysqJ9+/aMHj2a0NBQunXrBkCJEiXYu3cvAQEBXLx4kb59+6bYdPZNfHx8cHd3p2vXrpw9e5YjR44wZswYvTolSpQgJCQEf39/rl+/zrx589QegGQuLi4EBwcTFBTE48eP9YakJevUqRNmZmZ07dqVP//8kwMHDjBw4EA6d+6cKatCFilSBBMTE+bPn8+NGzf4+eefmTx5sl4dPz8/wsPD6dChA6dOneLq1ausXbuWy5cvA0n7bcyaNYt58+Zx9epVzpw5w/z584Gk3oSPPvqI7777josXL3Lo0CG9uSZvUqJECbZu3UpQUBBnz57ls88+0+t9cXFxoWvXrvTo0YPt27cTHBzMwYMH2bhxo1pHp9PRrVs3Ro8eTYkSJd6PPb/Ee0uSiuyWPFn75fAnKxMjtP/f3p1HRXGlbQB/ukE22WQHN0BRRHEDIWiiRJk0xg3FqAwqCO7CpxKjcXDBJKiJiWOMaI5GICYiykSM0ShRXAYFQVEQJ4gbE5eIuLK4gNL1/UGsSQvRVpam2+d3Th/pqltV722hLi+37r1/9EjzESgiohcLCwvDrl27cPDgQYV1FGxsbFBZWYl79+4plL9x48ZfDuaNi4uDqakphg0bhkOHDsHPzw/NmjXDe++9V2MGwtdRaGgo7t69C5lMJo6BWLBgAXr27AmZTAZvb2/Y2NjAz89P6XNKpVIkJyfj4cOH8PDwwMSJExEdHa1QZujQoZg9ezbCwsLQvXt3pKenY+HChQpl/P394evri7fffhuWlpa1TmtrYGCAlJQU3LlzB7169cLIkSMxYMAArFmz5uU/jFo8nXo3KSkJLi4uWL58eY2BzObm5jhw4ADKy8vRr18/uLm5YcOGDeIjV0FBQVi1ahXWrl2Lzp07Y/DgwTh//rx4fGxsLJ48eQI3NzfMmjULn3zyiVKxrVy5Ei1atEDv3r0xZMgQyGQy9OzZU6HMunXrMHLkSEyfPh3Ozs6YNGmSQq8OUP09UFlZ2TTW+6ImTSIISk5c/RopLS2FiYkJSkpK6v8vUHs+BDLXAX1mAX9bAgDotuQXlDx8jP0RfdHeyqh+r0dE9IwGvcc1IEEQEB4ejuTkZBw6dAhOTk4K+0tKSsRfLv39/QEABQUFcHZ2RkZGBt544w2F8jdv3oSHhweOHDmCli1bYtiwYejfvz9mzpyJHTt2ICoqSqlHTZ73eT569AiFhYVwcHCAnp5e3T4AIhVIS0vDgAEDcOXKFZWs+cWfIdVTts3g7E+N7ZnHn4DqcRUlDx9zXAUR0XPMmDEDCQkJ+PHHH2FkZCSOkzAxMYG+vj5MTEwQGhqKiIgImJmZwdjYGOHh4fDy8qqRUADArFmz8P7776Nly5YAqmcF+u677/DOO+9g/fr16NOnT6PWj6gpqaiowM2bNxEVFYX33nuvaSwiTE0aH39qbM88/gRwsDYRkTLWrVuHkpISeHt7w9bWVnxt3bpVLPPPf/4TgwcPhr+/P/r27QsbGxts3769xrlSUlJw4cIFTJ8+XdwWFhYGR0dHeHp6orKy8oULrZLmS0tLg6Gh4V++NNmWLVvQtm1b3Lt3D5999pmqwyE1wJ6KxsakgojolSjztK6enh5iYmIQExPz3HIymQwymUxhm4GBgcIgVSJ3d3elZ1vSNMHBweLgfCJlMKlobGJS8b/Hn4z1q/8bSh8+UUVEREREVAt9fX20b99e1WEQqQU+/tTYno6peKA4pgJgTwURERERqScmFY3taVLx+AFQWT1tW5eWJvDpZI225lylkoiIiIjUDx9/amw6hoC2HvDkUfW4Cp3mCPRsi0DPtqqOjIiIiIjolbCnorFJJLWOqyAiIiIiUldMKlRBXKvi5vPLERERERGpASYVqlDLtLJERESaxNvbG7NmzRLf29vbY9WqVc89RiKRYMeOHXW+dn2dh4iUx6RCFZhUEBFREzVkyBD4+vrWui8tLQ0SiQSnT59+6fMeP34ckydPrmt4CqKiotC9e/ca269fv46BAwfW67WeFR8fD4lEUuP1zTff1Lr9z6+oqKgGjY1IFThQWxXEx584poKIiJqW0NBQ+Pv74+rVq2jVqpXCvri4OLi7u6Nr164vfV5LS8v6CvGFbGxsGuU6xsbGKCgoUNhmYmKCwYMHi++3bt2KRYsWKZRTx9W4KysroaOjo+owqAljT4UqcKA2EdFrSRAEPHj8QCUvZVYkB4DBgwfD0tIS8fHxCtvLy8uRlJSE0NBQ3L59GwEBAWjZsiUMDAzg6uqKLVu2PPe8zz7+dP78efTt2xd6enpwcXHBvn37ahwzb948dOjQAQYGBnB0dMTChQvx+HH1mk7x8fFYsmQJcnNzxR6ApzE/+/hTXl4e+vfvD319fZibm2Py5MkoLy8X9wcHB8PPzw+ff/45bG1tYW5ujhkzZojX+isSiQQ2NjYKL319fYX3JiYmNcq9KKmoqqpCaGgoHBwcoK+vj44dO+LLL7+sUS42NhadO3eGrq4ubG1tERYWJu67d+8epkyZAmtra+jp6aFLly7YtWsXgNp7eFatWgV7e/san0l0dDTs7OzQsWNHAMB3330Hd3d3GBkZwcbGBn//+99RXFyscK7//Oc/GDx4MIyNjWFkZIS33noLFy9exL///W80a9YMRUVFCuVnzZqFt95667mfCTV97KlQBQMO1CYieh09fPIQngmeKrl25t8zYdDsxeshaWtrY/z48YiPj0dkZCQkEgkAICkpCVVVVQgICEB5eTnc3Nwwb948GBsbY/fu3Rg3bhzatWsHDw+PF15DLpdjxIgRsLa2RmZmJkpKShTGXzxlZGSE+Ph42NnZIS8vD5MmTYKRkRHmzp2L0aNH48yZM9i7dy/2798PoLqX4Fn379+HTCaDl5cXjh8/juLiYkycOBFhYWEKidPBgwdha2uLgwcP4sKFCxg9ejS6d++OSZMmvbA+9U0ul6NVq1ZISkqCubk50tPTMXnyZNja2mLUqFEAgHXr1iEiIgLLly/HwIEDUVJSgqNHj4rHDxw4EGVlZfj+++/Rrl07/Prrr9DS0nqpOFJTU2FsbKyQ8D1+/Bgff/wxOnbsiOLiYkRERCA4OBg///wzAODatWvo27cvvL29ceDAARgbG+Po0aN48uQJ+vbtC0dHR3z33Xf44IMPxPNt3rwZn332WX18dKRCTCpUgT0VRETUhIWEhGDFihU4fPgwvL29AVQ/+uTv7w8TExOYmJhgzpw5Yvnw8HCkpKRg27ZtSiUV+/fvx9mzZ5GSkgI7OzsAwNKlS2uMg1iwYIH4tb29PebMmYPExETMnTsX+vr6MDQ0hLa29nMfd0pISMCjR4+wadMmNG/eHACwZs0aDBkyBJ9++imsra0BAC1atMCaNWugpaUFZ2dnDBo0CKmpqc9NKkpKShR6HQwNDWv8Ff5VNGvWDEuWLBHfOzg4ICMjA9u2bROTik8++QTvv/8+Zs6cKZbr1asXgOrPNysrC/n5+ejQoQMAwNHR8aXjaN68Ob755huFx55CQkLErx0dHbF69Wr06tUL5eXlMDQ0RExMDExMTJCYmIhmzZoBgBgDUP14XVxcnJhU/PTTT3j06JFYL1JfTCpUgVPKEhG9lvS19ZH590yVXVtZzs7O6N27N2JjY+Ht7Y0LFy4gLS0NH330EYDqx3OWLl2Kbdu24dq1a6isrERFRQUMDF7cEwIA+fn5aN26tZhQAICXl1eNclu3bsXq1atx8eJFlJeX48mTJzA2Nla6Hk+v1a1bNzGhAIA+ffpALpejoKBATCo6d+6s8Jd8W1tb5OXlPffcRkZGOHnypPheKq2/p8pjYmIQGxuLy5cv4+HDh6isrBQfWSouLsbvv/+OAQMG1HpsTk4OWrVqpfDL/KtwdXWtMY4iOzsbUVFRyM3Nxd27dyGXywEAly9fhouLC3JycvDWW2+JCcWzgoODsWDBAhw7dgxvvPEG4uPjMWrUKIX/H1JPTCpU4WlPxYNbgFwO1ONNiIiImi6JRKLUI0hNQWhoKMLDwxETE4O4uDi0a9cO/fr1AwCsWLECX375JVatWgVXV1c0b94cs2bNQmVlZb1dPyMjA4GBgViyZAlkMpn41+8vvvii3q7xZ8/+EiyRSMRfmP+KVCpF+/bt6z2WxMREzJkzB1988QW8vLxgZGSEFStWIDOzOiHV139+gvii/VKptMYYm9rGjzz7i/7TR8lkMhk2b94MS0tLXL58GTKZTPy/f9G1raysMGTIEMTFxcHBwQF79uzBoUOHnnsMqQf+NqsKT3sq5E+AR/dUGgoREVFtRo0aBalUioSEBGzatAkhISHi+IqjR49i2LBhGDt2LLp16wZHR0ecO3dO6XN36tQJV65cwfXr18Vtx44dUyiTnp6Otm3bIjIyEu7u7nBycsJvv/2mUEZHRwdVVVUvvFZubi7u378vbjt69CikUqk4+LipOXr0KHr37o3p06ejR48eaN++PS5evCjuNzIygr29PVJTU2s9vmvXrrh69epf/p9YWlqiqKhIIbHIycl5YVxnz57F7du3sXz5crz11ltwdnauMUi7a9euSEtLe+4g94kTJ2Lr1q1Yv3492rVrhz59+rzw2tT0MalQBW1dQPePwWQcV0FERE2QoaEhRo8ejfnz5+P69esIDg4W9zk5OWHfvn1IT09Hfn4+pkyZghs3bih9bh8fH3To0AFBQUHIzc1FWloaIiMjFco4OTnh8uXLSExMxMWLF7F69WokJycrlLG3t0dhYSFycnJw69YtVFRU1LhWYGAg9PT0EBQUhDNnzuDgwYMIDw/HuHHjxEefmhonJyecOHECKSkpOHfuHBYuXIjjx48rlImKisIXX3yB1atX4/z58zh58iS++uorAEC/fv3Qt29f+Pv7Y9++fSgsLMSePXuwd+9eANULE968eROfffYZLl68iJiYGOzZs+eFcbVp0wY6Ojr46quvcOnSJezcuRMff/yxQpmwsDCUlpZizJgxOHHiBM6fP4/vvvtOYUpdmUwGY2NjfPLJJ5gwYUJdPy5qIphUqArHVRARURMXGhqKu3fvQiaTKYx/WLBgAXr27AmZTAZvb2/Y2NjAz89P6fNKpVIkJyfj4cOH8PDwwMSJExEdHa1QZujQoZg9ezbCwsLQvXt3pKenY+HChQpl/P394evri7fffhuWlpa1TmtrYGCAlJQU3LlzB7169cLIkSMxYMAArFmz5uU+jEY0ZcoUjBgxAqNHj4anpydu376N6dOnK5QJCgrCqlWrsHbtWnTu3BmDBw/G+fPnxf0//PADevXqhYCAALi4uGDu3Llir06nTp2wdu1axMTEoFu3bsjKylIYeP9Xnk41nJSUBBcXFyxfvhyff/65Qhlzc3McOHAA5eXl6NevH9zc3LBhwwaFx8ukUimCg4NRVVWF8ePH1+WjoiZEIig7cfVrpLS0FCYmJigpKXnpAWFK2ygDrhwDRm0CXIY1zDWIiGrRKPe418jzPs9Hjx6hsLAQDg4O0NPTU1GERE1PaGgobt68iZ07dz63HH+GVE/ZNqNJ9FTExMTA3t4eenp68PT0RFZW1l+W9fb2rnXJ+0GDBollgoODa+z39fVtjKoojz0VRERE9JopKSnBkSNHkJCQgPDwcFWHQ/VI5UnF1q1bERERgcWLF+PkyZPo1q0bZDJZjYE/T23fvh3Xr18XX2fOnIGWlhbee+89hXK+vr4K5V600mejE5MKjqkgIiJ6nUydOhWGhoa1vqZOnarq8BrUsGHD8M4772Dq1Kn429/+pupwqB6pfErZlStXYtKkSeJAna+//hq7d+9GbGwsPvzwwxrlzczMFN4nJibCwMCgRlKhq6v73MVwVE5cAI89FURERK+Tjz766C/HMGj6I4mcPlZzqTSpqKysRHZ2NubPny9uk0ql8PHxQUZGhlLn2LhxI8aMGVNjLuVDhw7BysoKLVq0QP/+/fHJJ5/A3Ny81nNUVFQozBhRWlr6CrV5SYZ/zDhR+nvDX4uIiIiaDCsrK1hZWak6DKJ6pdLHn27duoWqqqoaU7pZW1srtcx9VlYWzpw5g4kTJyps9/X1xaZNm5CamopPP/0Uhw8fxsCBA/9yLutly5bBxMREfLVu3frVK6Us8z8Wy7ml/LzeRERERERNkcoff6qLjRs3wtXVFR4eHgrbx4wZI37t6uqKrl27ol27djh06FCtS9rPnz8fERER4vvS0tKGTyws/1hw504h8KSieu0KIiIiIiI1pNKeCgsLC2hpadVYMOfGjRsvHA9x//59JCYmIjQ09IXXcXR0hIWFBS5cuFDrfl1dXRgbGyu8GpyRLaBjBAhVwO2LLy5PRERERNREqTSp0NHRgZubm8Iy83K5HKmpqfDy8nrusUlJSaioqMDYsWNfeJ2rV6/i9u3bsLW1rXPM9UYi+V9vxa2C55clIiIiImrCVD6lbEREBDZs2IBvv/0W+fn5mDZtGu7fvy/OBjV+/HiFgdxPbdy4EX5+fjUGX5eXl+ODDz7AsWPH8N///hepqakYNmwY2rdvD5lM1ih1UtrTpOImx1UQERERkfpSeVIxevRofP7551i0aBG6d++OnJwc7N27Vxy8ffnyZVy/fl3hmIKCAhw5cqTWR5+0tLRw+vRpDB06FB06dEBoaCjc3NyQlpYGXd0mNm7BokP1vzfPqjYOIiKieuTt7Y1Zs2aJ7+3t7bFq1arnHiORSLBjx44GjYuIGk6TGKgdFhaGsLCwWvfVNp9xx44dIQhCreX19fWRkpJSn+E1HEvn6n85AxQRETURQ4YMwePHj7F3794a+9LS0tC3b1/k5uaia9euSp/z+PHjNaZ+JyLNovKeitea5R89FbfOA/Lap7slIiJqTKGhodi3bx+uXr1aY19cXBzc3d1fKqEAAEtLSxgYGNRXiE1OZWWlqkMgUjkmFapk2hbQ0gWqKoC7/1V1NERE1MAEQYD8wQOVvP6qh/9ZgwcPhqWlJeLj4xW2l5eXIykpCX5+fggICEDLli1hYGAAV1dXbNmy5bnnfPbxp/Pnz6Nv377Q09ODi4sL9u3b91Kf47x589ChQwcYGBjA0dERCxcuxOPHjxXK/PTTT+jVqxf09PRgYWGB4cOHi/sqKiowb948tG7dGrq6umjfvj02btwIAIiPj4epqanCuXbs2AGJRCK+j4qKQvfu3fHNN9/AwcEBenp6AIC9e/fizTffhKmpKczNzTF48GBcvKg4w+PVq1cREBAAMzMzNG/eHO7u7sjMzMR///tfSKVSnDhxQqH8qlWr0LZtW8jl8pf6jIgaW5N4/Om1JdWqHldxI6/6ESjzdqqOiIiIGpDw8CEKerqp5NodT2ZDokRvgba2NsaPH4/4+HhERkaKv0wnJSWhqqoKY8eORVJSEubNmwdjY2Ps3r0b48aNQ7t27WqsG1UbuVyOESNGwNraGpmZmSgpKVEYf6EMIyMjxMfHw87ODnl5eZg0aRKMjIwwd+5cAMDu3bsxfPhwREZGYtOmTaisrMTPP/8sHj9+/HhkZGRg9erV6NatGwoLC3Hr1q2XiuHChQv44YcfsH37dmhpaQGonu4+IiICXbt2RXl5ORYtWoThw4cjJycHUqkU5eXl6NevH1q2bImdO3fCxsYGJ0+ehFwuh729PXx8fMTeoKfi4uIQHBwMqZR/B6amjUmFqln+kVTcLAA6DlR1NERERAgJCcGKFStw+PBheHt7A6j+5dbf3x9t27bFnDlzxLLh4eFISUnBtm3blEoq9u/fj7NnzyIlJQV2dnYAgKVLl2LgQOXbwAULFohf29vbY86cOUhMTBSTiujoaIwZMwZLliwRy3Xr1g0AcO7cOWzbtg379u2Dj48PgOr1rF5WZWUlNm3aBEtLS3Gbv7+/QpnY2FhYWlri119/RZcuXZCQkICbN2/i+PHjMDMzAwC0b99eLD9x4kRMnToVK1euhK6uLk6ePIm8vDz8+OOPLx0fUWNjUqFqFk+nleVaFUREmk6ir4+OJ7NVdm1lOTs7o3fv3oiNjYW3tzcuXLiAtLQ0fPTRR6iqqsLSpUuxbds2XLt2DZWVlaioqFB6zER+fj5at24tJhQAXrg21bO2bt2K1atX4+LFiygvL8eTJ08UFq7NycnBpEmTaj02JycHWlpa6Nev30td81lt27ZVSCiA6se6Fi1ahMzMTNy6dUt8ZOny5cvo0qULcnJy0KNHDzGheJafnx9mzJiB5ORkjBkzBvHx8Xj77bdhb29fp1iJGgP70lSNC+AREb02JBIJpAYGKnn9eUyAMkJDQ/HDDz+grKwMcXFxaNeuHfr164cVK1bgyy+/xLx583Dw4EHk5ORAJpM12mDljIwMBAYG4t1338WuXbtw6tQpREZGKlxf/zkJ1PP2AYBUKq0x/uTZ8RoAap3NasiQIbhz5w42bNiAzMxMZGZmAvjfQO4XXVtHRwfjx49HXFwcKisrkZCQgJCQkOceQ9RUMKlQtT8vgKfkIDoiIqKGNmrUKEilUiQkJGDTpk0ICQmBRCLB0aNHMWzYMIwdOxbdunWDo6Mjzp1Tfmr0Tp064cqVKwprUB07dkzp49PT09G2bVtERkbC3d0dTk5O+O233xTKdO3aFampqbUe7+rqCrlcjsOHD9e639LSEmVlZbh//764LScn54Vx3b59GwUFBViwYAEGDBiATp064e7duzXiysnJwZ07d/7yPBMnTsT+/fuxdu1aPHnyBCNGjHjhtYmaAiYVqmbWDpBoAZVlQOnvqo6GiIgIAGBoaIjRo0dj/vz5uH79OoKDgwEATk5O2LdvH9LT05Gfn48pU6bgxo0bSp/Xx8cHHTp0QFBQEHJzc5GWlobIyEilj3dycsLly5eRmJiIixcvYvXq1UhOTlYos3jxYmzZsgWLFy9Gfn4+8vLy8OmnnwKoHoMRFBSEkJAQ7NixA4WFhTh06BC2bdsGAPD09ISBgQH+8Y9/4OLFi0hISKgxE1ZtWrRoAXNzc6xfvx4XLlzAgQMHEBERoVAmICAANjY28PPzw9GjR3Hp0iX88MMPyMjIEMt06tQJb7zxBubNm4eAgIAX9m4QNRVMKlRNWwcwc6j+mo9AERFRExIaGoq7d+9CJpOJYyAWLFiAnj17QiaTwdvbW/wlWVlSqRTJycl4+PAhPDw8MHHiRERHRyt9/NChQzF79myEhYWhe/fuSE9Px8KFCxXKeHt7IykpCTt37kT37t3Rv39/ZGVlifvXrVuHkSNHYvr06XB2dsakSZPEngkzMzN8//33+Pnnn8XpcqOiopSqV2JiIrKzs9GlSxfMnj0bK1asUCijo6ODX375BVZWVnj33Xfh6uqK5cuXi7NHPRUaGorKyko++kRqRSIoO3H1a6S0tBQmJiYoKSlRGPjVYBIDgbO7AN9PgTemNvz1iOi11uj3OA33vM/z0aNHKCwsVFjLgOhFPv74YyQlJeH06dOqDkXl+DOkesq2GeypaAos/lhZu7Tm6qVERET0eigvL8eZM2ewZs0ahIeHqzocopfCpKIp6B0OfHgZeOcTVUdCRESkUkuXLoWhoWGtr5dZy0IdhYWFwc3NDd7e3nz0idQO16loCgxqn6+aiIjodTN16lSMGjWq1n2aPmg5Pj5eqUHhRE0RkwoiIiJqMszMzP5ycTgiarr4+BMREVED45woRK+GPzvqg0kFERFRA2nWrBkA4MGDByqOhEg9Pf3ZefqzRE0XH38iIiJqIFpaWjA1NUVxcTEAwMDAABKJRMVRETV9giDgwYMHKC4uhqmpaY21PKjpYVJBRETUgGxsbABATCyISHmmpqbizxA1bUwqiIiIGpBEIoGtrS2srKzw+PFjVYdDpDaaNWvGHgo1wqSCiIioEWhpafEXJCLSWByoTUREGiUmJgb29vbQ09ODp6cnsrKyxH0REREwMzND69atsXnzZoXjkpKSMGTIkMYOl4hII7CngoiINMbWrVsRERGBr7/+Gp6enli1ahVkMhkKCgqQmZmJhIQE/PLLLzh//jxCQkIgk8lgYWGBkpISREZGYv/+/aquAhGRWmJPBRERaYyVK1di0qRJmDBhAlxcXPD111/DwMAAsbGxyM/Ph7e3N9zd3REQEABjY2MUFhYCAObOnYtp06ahTZs2Kq4BEZF6Yk9FLZ4utFJaWqriSIiI6t/Te5umLSpVWVmJ7OxszJ8/X9wmlUrh4+ODjIwMTJ8+HevXr8fdu3dx6dIlPHz4EO3bt8eRI0dw8uRJrF27VqnrVFRUoKKiQnxfUlICgG0GEWkmZdsMJhW1KCsrAwC0bt1axZEQETWcsrIymJiYqDqMenPr1i1UVVXB2tpaYbu1tTXOnj0LmUyGsWPHolevXtDX18e3336L5s2bY9q0aYiPj8e6devw1VdfwcLCAuvXr0fnzp1rvc6yZcuwZMmSGtvZZhCRJntRmyERNO1PVfVALpfj999/h5GR0UstUlRaWorWrVvjypUrMDY2bsAIVYd11Ayso2Z41ToKgoCysjLY2dlBKtWcp2B///13tGzZEunp6fDy8hK3z507F4cPH0ZmZmaNY5YsWYJ79+5hwoQJeOedd5CXl4ddu3ZhzZo1yM7OrvU6z/ZUyOVy3LlzB+bm5mwznsE6agbWUf3VpX7KthnsqaiFVCpFq1atXvl4Y2NjjfyG/DPWUTOwjprhVeqoST0UT1lYWEBLSws3btxQ2H7jxo1aF886e/Ysvv/+e5w6dQqxsbHo27cvLC0tMWrUKISEhKCsrAxGRkY1jtPV1YWurq7CNlNT01eOm9+jmoF11AyaXsdXrZ8ybYbm/ImKiIheazo6OnBzc0Nqaqq4TS6XIzU1VaHnAqj+y9uUKVOwcuVKGBoaoqqqSlyY7um/VVVVjRc8EZGaY08FERFpjIiICAQFBcHd3R0eHh5YtWoV7t+/jwkTJiiU++abb2BpaSmuS9GnTx9ERUXh2LFj2LNnD1xcXOrU+0BE9LphUlGPdHV1sXjx4hrd4pqEddQMrKNmeB3q+LJGjx6NmzdvYtGiRSgqKkL37t2xd+9ehcHbN27cQHR0NNLT08VtHh4eeP/99zFo0CBYWVnh22+/bfBYX4f/P9ZRM7CO6q8x6seB2kREREREVCccU0FERERERHXCpIKIiIiIiOqESQUREREREdUJkwoiIiIiIqoTJhX1KCYmBvb29tDT04OnpyeysrJUHdIrWbZsGXr16gUjIyNYWVnBz88PBQUFCmUePXqEGTNmwNzcHIaGhvD396+x4JQ6Wb58OSQSCWbNmiVu04Q6Xrt2DWPHjoW5uTn09fXh6uqKEydOiPsFQcCiRYtga2sLfX19+Pj44Pz58yqM+OVUVVVh4cKFcHBwgL6+Ptq1a4ePP/4Yf55/Qt3q+O9//xtDhgyBnZ0dJBIJduzYobBfmfrcuXMHgYGBMDY2hqmpKUJDQ1FeXt6ItSBlsM1Qr/vpn7HNUI/76bPYZjRwmyFQvUhMTBR0dHSE2NhY4T//+Y8wadIkwdTUVLhx44aqQ3tpMplMiIuLE86cOSPk5OQI7777rtCmTRuhvLxcLDN16lShdevWQmpqqnDixAnhjTfeEHr37q3CqF9dVlaWYG9vL3Tt2lWYOXOmuF3d63jnzh2hbdu2QnBwsJCZmSlcunRJSElJES5cuCCWWb58uWBiYiLs2LFDyM3NFYYOHSo4ODgIDx8+VGHkyouOjhbMzc2FXbt2CYWFhUJSUpJgaGgofPnll2IZdavjzz//LERGRgrbt28XAAjJyckK+5Wpj6+vr9CtWzfh2LFjQlpamtC+fXshICCgkWtCz8M2Q73up3/GNkN97qfPYpvRsG0Gk4p64uHhIcyYMUN8X1VVJdjZ2QnLli1TYVT1o7i4WAAgHD58WBAEQbh3757QrFkzISkpSSyTn58vABAyMjJUFeYrKSsrE5ycnIR9+/YJ/fr1ExsITajjvHnzhDfffPMv98vlcsHGxkZYsWKFuO3evXuCrq6usGXLlsYIsc4GDRokhISEKGwbMWKEEBgYKAiC+tfx2QZCmfr8+uuvAgDh+PHjYpk9e/YIEolEuHbtWqPFTs/HNkO97qdPsc1Q3/upILDNEISGbTP4+FM9qKysRHZ2Nnx8fMRtUqkUPj4+yMjIUGFk9aOkpAQAYGZmBgDIzs7G48ePFerr7OyMNm3aqF19Z8yYgUGDBinUBdCMOu7cuRPu7u547733YGVlhR49emDDhg3i/sLCQhQVFSnU0cTEBJ6enmpTx969eyM1NRXnzp0DAOTm5uLIkSMYOHAgAM2o458pU5+MjAyYmprC3d1dLOPj4wOpVIrMzMxGj5lqYpuhfvfTp9hmqPf9lG1Gw7YZXFG7Hty6dQtVVVUKK7YCgLW1Nc6ePauiqOqHXC7HrFmz0KdPH3Tp0gUAUFRUBB0dHZiamiqUtba2RlFRkQqifDWJiYk4efIkjh8/XmOfJtTx0qVLWLduHSIiIvCPf/wDx48fx//93/9BR0cHQUFBYj1q+75Vlzp++OGHKC0thbOzM7S0tFBVVYXo6GgEBgYCgEbU8c+UqU9RURGsrKwU9mtra8PMzEwt66yJ2GZUU7efQ7YZ6n8/ZZsB8X1DtBlMKui5ZsyYgTNnzuDIkSOqDqVeXblyBTNnzsS+ffugp6en6nAahFwuh7u7O5YuXQoA6NGjB86cOYOvv/4aQUFBKo6ufmzbtg2bN29GQkICOnfujJycHMyaNQt2dnYaU0cidcI2Q32xzdCMOqoSH3+qBxYWFtDS0qoxy8ONGzdgY2OjoqjqLiwsDLt27cLBgwfRqlUrcbuNjQ0qKytx7949hfLqVN/s7GwUFxejZ8+e0NbWhra2Ng4fPozVq1dDW1sb1tbWal9HW1tbuLi4KGzr1KkTLl++DABiPdT5+/aDDz7Ahx9+iDFjxsDV1RXjxo3D7NmzsWzZMgCaUcc/U6Y+NjY2KC4uVtj/5MkT3LlzRy3rrInYZlRTp/qyzdCM+ynbDIjvG6LNYFJRD3R0dODm5obU1FRxm1wuR2pqKry8vFQY2asRBAFhYWFITk7GgQMH4ODgoLDfzc0NzZo1U6hvQUEBLl++rDb1HTBgAPLy8pCTkyO+3N3dERgYKH6t7nXs06dPjWkdz507h7Zt2wIAHBwcYGNjo1DH0tJSZGZmqk0dHzx4AKlU8TampaUFuVwOQDPq+GfK1MfLywv37t1Ddna2WObAgQOQy+Xw9PRs9JipJrYZ6nc/ZZuhGfdTthkN3GbUZZQ5/U9iYqKgq6srxMfHC7/++qswefJkwdTUVCgqKlJ1aC9t2rRpgomJiXDo0CHh+vXr4uvBgwdimalTpwpt2rQRDhw4IJw4cULw8vISvLy8VBh13f15Jg9BUP86ZmVlCdra2kJ0dLRw/vx5YfPmzYKBgYHw/fffi2WWL18umJqaCj/++KNw+vRpYdiwYU166rxnBQUFCS1bthSnB9y+fbtgYWEhzJ07VyyjbnUsKysTTp06JZw6dUoAIKxcuVI4deqU8NtvvwmCoFx9fH19hR49egiZmZnCkSNHBCcnJ04p28SwzVCv+2lt2GY0/fvps9hmNGybwaSiHn311VdCmzZtBB0dHcHDw0M4duyYqkN6JQBqfcXFxYllHj58KEyfPl1o0aKFYGBgIAwfPly4fv266oKuB882EJpQx59++kno0qWLoKurKzg7Owvr169X2C+Xy4WFCxcK1tbWgq6urjBgwAChoKBARdG+vNLSUmHmzJlCmzZtBD09PcHR0VGIjIwUKioqxDLqVseDBw/W+vMXFBQkCIJy9bl9+7YQEBAgGBoaCsbGxsKECROEsrIyFdSGnodthnrdT5/FNqPp30+fxTajYdsMiSD8aRlBIiIiIiKil8QxFUREREREVCdMKoiIiIiIqE6YVBARERERUZ0wqSAiIiIiojphUkFERERERHXCpIKIiIiIiOqESQUREREREdUJkwoiIiIiIqoTJhVEakwikWDHjh2qDoOIiJo4thfU0JhUEL2i4OBgSCSSGi9fX19Vh0ZERE0I2wt6HWirOgAidebr64u4uDiFbbq6uiqKhoiImiq2F6Tp2FNBVAe6urqwsbFReLVo0QJAdVfzunXrMHDgQOjr68PR0RH/+te/FI7Py8tD//79oa+vD3Nzc0yePBnl5eUKZWJjY9G5c2fo6urC1tYWYWFhCvtv3bqF4cOHw8DAAE5OTti5c2fDVpqIiF4a2wvSdEwqiBrQwoUL4e/vj9zcXAQGBmLMmDHIz88HANy/fx8ymQwtWrTA8ePHkZSUhP379ys0AuvWrcOMGTMwefJk5OXlYefOnWjfvr3CNZYsWYJRo0bh9OnTePfddxEYGIg7d+40aj2JiKhu2F6Q2hOI6JUEBQUJWlpaQvPmzRVe0dHRgiAIAgBh6tSpCsd4enoK06ZNEwRBENavXy+0aNFCKC8vF/fv3r1bkEqlQlFRkSAIgmBnZydERkb+ZQwAhAULFojvy8vLBQDCnj176q2eRERUN2wv6HXAMRVEdfD2229j3bp1CtvMzMzEr728vBT2eXl5IScnBwCQn5+Pbt26oXnz5uL+Pn36QC6Xo6CgABKJBL///jsGDBjw3Bi6du0qft28eXMYGxujuLj4VatEREQNgO0FaTomFUR10Lx58xrdy/VFX19fqXLNmjVTeC+RSCCXyxsiJCIiekVsL0jTcUwFUQM6duxYjfedOnUCAHTq1Am5ubm4f/++uP/o0aOQSqXo2LEjjIyMYG9vj9TU1EaNmYiIGh/bC1J37KkgqoOKigoUFRUpbNPW1oaFhQUAICkpCe7u7njzzTexefNmZGVlYePGjQCAwMBALF68GEFBQYiKisLNmzcRHh6OcePGwdraGgAQFRWFqVOnwsrKCgMHDkRZWRmOHj2K8PDwxq0oERHVCdsL0nRMKojqYO/evbC1tVXY1rFjR5w9exZA9UwbiYmJmD59OmxtbbFlyxa4uLgAAAwMDJCSkoKZM2eiV69eMDAwgL+/P1auXCmeKygoCI8ePcI///lPzJkzBxYWFhg5cmTjVZCIiOoF2wvSdBJBEARVB0GkiSQSCZKTk+Hn56fqUIiIqAlje0GagGMqiIiIiIioTphUEBERERFRnfDxJyIiIiIiqhP2VBARERERUZ0wqSAiIiIiojphUkFERERERHXCpIKIiIiIiOqESQUREREREdUJkwoiIiIiIqoTJhVERERERFQnTCqIiIiIiKhO/h8XLJXqVuEmDgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "for param in trainer.model.parameters(): # Access model via trainer\n",
        "    param.requires_grad = True\n",
        "\n",
        "learning_rate_finetune = 1e-5\n",
        "\n",
        "optimizer_finetune = torch.optim.AdamW(trainer.model.parameters(), lr=learning_rate_finetune, weight_decay=weight_decay)\n",
        "\n",
        "# Update the optimizer within the trainer object\n",
        "trainer.optimizer = optimizer_finetune\n",
        "print(f\"Switched to new optimizer with LR: {learning_rate_finetune}\")\n",
        "\n",
        "# 3. Continue training for a few more epochs\n",
        "num_finetune_epochs = 2 # Example: Train for 15 more epochs\n",
        "start_finetune_epoch = best_epoch # Continue epoch numbering for logging\n",
        "\n",
        "trainer.test(valid_loader, \"Validation\", start_finetune_epoch)\n",
        "\n",
        "for epoch in range(start_finetune_epoch, start_finetune_epoch + num_finetune_epochs):\n",
        "    print(f\"Fine-tuning epoch: {epoch}\")\n",
        "    # Use the same training method, it will now use the new optimizer\n",
        "    trainer.train(train_loader, epoch, )\n",
        "\n",
        "    print(f\"Validating fine-tuning epoch: {epoch}\")\n",
        "    val_acc = trainer.test(valid_loader, \"Validation FT\", epoch)\n",
        "\n",
        "    trainer.save_model(f\"models/{name}_{epoch}_ft.pth\", model_name=f\"history/{name}_ft\")\n",
        "    \n",
        "    if val_acc > best_accuracy:\n",
        "        best_accuracy = val_acc\n",
        "        best_model_file = f\"models/{name}_{epoch}_ft.pth\"\n",
        "        best_epoch = epoch\n",
        "        print(f\"New best accuracy: {best_accuracy}\")\n",
        "\n",
        "print(f\"\\nTraining finished. Best overall validation accuracy: {best_epoch:.4f}\")\n",
        "\n",
        "trainer.plot_model(model_name=\"MobileNet_FT\", path=f\"plots/{name}_ft.jpg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
